{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zal4c0uZhz9Y"
   },
   "source": [
    "# ID R&D antispoofing challenge baseline\n",
    "\n",
    "Реализуем простой бейзлайн на основе предобученной сети ResNet18. Сеть будет делать предсказания для каждого кадра отдельно. Для получения предсказания для каждого видео будем усреднять покадровые вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2890,
     "status": "ok",
     "timestamp": 1552820981947,
     "user": {
      "displayName": "Emil Kayumov",
      "photoUrl": "https://lh6.googleusercontent.com/-oirNfjt5c08/AAAAAAAAAAI/AAAAAAAABOM/sesD6gzdlUw/s64/photo.jpg",
      "userId": "02485254328338509836"
     },
     "user_tz": -180
    },
    "id": "mWyjteadhz9e",
    "outputId": "51e37257-27db-4d41-ae33-a0cc2b583813"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../train_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно обучать модели в Google Colab, а данные для них загружать из личного Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19887,
     "status": "ok",
     "timestamp": 1552821004941,
     "user": {
      "displayName": "Emil Kayumov",
      "photoUrl": "https://lh6.googleusercontent.com/-oirNfjt5c08/AAAAAAAAAAI/AAAAAAAABOM/sesD6gzdlUw/s64/photo.jpg",
      "userId": "02485254328338509836"
     },
     "user_tz": -180
    },
    "id": "yC-ZrpB6hz96",
    "outputId": "3191daf1-06df-4803-fecc-3abb89b7e788"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# path_data = '/content/drive/My Drive/idrnd/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOjk8mQWhz-D"
   },
   "source": [
    "Загрузим пути до всех изображений (сами изображения не будем держать в памяти, а будем загружать их при подготовке очередного батча)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHGwpKhjhz-F"
   },
   "outputs": [],
   "source": [
    "path_images = []\n",
    "\n",
    "for label in ['2dmask', 'real', 'printed', 'replay']:\n",
    "    videos = os.listdir(os.path.join(path_data, label))\n",
    "    for video in videos:\n",
    "        frames = os.listdir(os.path.join(path_data, label, video))\n",
    "        for frame in frames:\n",
    "            path_images.append({\n",
    "                'path': os.path.join(path_data, label, video, frame),\n",
    "                'label': int(label != 'real'),\n",
    "                'video': video})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqUK9QVNhz-O"
   },
   "source": [
    "Подготовим торчовый датасет для наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLen8tLrhz-U"
   },
   "outputs": [],
   "source": [
    "class AntispoofDataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, paths, transform=None,\n",
    "                 loader=torchvision.datasets.folder.default_loader):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_info = self.paths[index]\n",
    "\n",
    "        img = self.loader(image_info['path'])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, image_info['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxVvr-hihz-d"
   },
   "source": [
    "Разделим выборку на обучающую и контрольную. Так как объектов у нашей модели выступает кадр из видео, то необходимо делить выборку так, чтобы кадры одного видео попадали либо целиком в обучающую выборку, либо целиком в тестовую выборку (иначе будем переобучаться)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1OUij49hz-k"
   },
   "outputs": [],
   "source": [
    "test_fraction = 0.1\n",
    "\n",
    "videos = list(set(x['video'] for x in path_images))\n",
    "videos_tr, videos_ts = train_test_split(videos, test_size=0.1, random_state=123)\n",
    "\n",
    "train_path_images = [x for x in path_images if x['video'] in videos_tr]\n",
    "test_path_images = [x for x in path_images if x['video'] in videos_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZmXOAPXhz-2"
   },
   "source": [
    "Подготовим генераторы для данных. Для обучения добавим немного аугментаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViWwvEtKhz-8"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    'val': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': AntispoofDataset(\n",
    "        train_path_images, transform=data_transforms['train']),\n",
    "    'val': AntispoofDataset(\n",
    "        test_path_images, transform=data_transforms['val'])}\n",
    "\n",
    "dataloaders = {\n",
    "  x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=256, shuffle=True, num_workers=4)\n",
    "    for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKHaRnpnhz_B"
   },
   "source": [
    "Возьмём за основу предобученный ResNet18. Заменим последний полносвязный слой, так как нам необходимо предсказывать только 1 класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 109415,
     "status": "ok",
     "timestamp": 1552821128311,
     "user": {
      "displayName": "Emil Kayumov",
      "photoUrl": "https://lh6.googleusercontent.com/-oirNfjt5c08/AAAAAAAAAAI/AAAAAAAABOM/sesD6gzdlUw/s64/photo.jpg",
      "userId": "02485254328338509836"
     },
     "user_tz": -180
    },
    "id": "xhTM2Krthz_H",
    "outputId": "e0997cc5-8b42-4c21-ca2e-d07a4245b139"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoHfQ7l_hz_d"
   },
   "source": [
    "Обучим сеть. Будем запоминать лучшую по точности модель на отложенной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1751
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 888331,
     "status": "ok",
     "timestamp": 1552825359399,
     "user": {
      "displayName": "Emil Kayumov",
      "photoUrl": "https://lh6.googleusercontent.com/-oirNfjt5c08/AAAAAAAAAAI/AAAAAAAABOM/sesD6gzdlUw/s64/photo.jpg",
      "userId": "02485254328338509836"
     },
     "user_tz": -180
    },
    "id": "DY1VVNLshz_h",
    "outputId": "42070c31-1afd-4f0b-eb03-f64744f9fb6f"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "since = time.time()\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # iterate over data\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).view(-1)\n",
    "                preds = (outputs > 0).long()\n",
    "                loss = criterion(outputs, labels.float())\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print('{}\\tLoss: {:.4f}\\tAcc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSBAzTRQhz_m",
    "scrolled": true
   },
   "source": [
    "Сохраним модель. Она нам пригодится в скрипте для инференса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wRHGwdrhz_s"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
