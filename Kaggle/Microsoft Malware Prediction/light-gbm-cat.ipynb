{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import warnings\n",
    "import gc\n",
    "import pickle\n",
    "import time\n",
    "import kaggle\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script started:  Mar 12 2019 20:04:54\n",
      "TRAIN LOADED\n"
     ]
    }
   ],
   "source": [
    "print(\"script started: \", time.strftime(\"%b %d %Y %H:%M:%S\"))\n",
    "\n",
    "\n",
    "train_fname = '../input/light-gbm-data-ms/train_cat.pkl'\n",
    "test_fname = '../input/light-gbm-data-ms/test_cat.pkl'\n",
    "\n",
    "train = pd.read_pickle(train_fname)\n",
    "print(\"TRAIN LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2bbf2e232efbae339dfb110d608c18c8262c2b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN PREPARED\n",
      "TEST LOADED\n"
     ]
    }
   ],
   "source": [
    "target = pd.read_pickle('../input/light-gbm-data-ms/target.pkl')\n",
    "\n",
    "\n",
    "true_numerical_columns = [\n",
    "    'Census_ProcessorCoreCount',\n",
    "    'Census_PrimaryDiskTotalCapacity',\n",
    "    'Census_SystemVolumeTotalCapacity',\n",
    "    'Census_TotalPhysicalRAM',\n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "    'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "    'Census_InternalBatteryNumberOfCharges'\n",
    "]\n",
    "\n",
    "binary_variables = [c for c in train.columns if train[c].nunique() == 2]\n",
    "\n",
    "categorical_columns = [c for c in train.columns if c not in true_numerical_columns]\n",
    "\n",
    "\n",
    "#max_iter = 3\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"TRAIN PREPARED\")\n",
    "\n",
    "\n",
    "test = pd.read_pickle(test_fname)\n",
    "print(\"TEST LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dbd38f95d83a2fd0301eee34c33a9d4f938a51fc"
   },
   "outputs": [],
   "source": [
    "experinment_nr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fe29efddb4968844552a173c49febbc5210181c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7845c2633909d4f016ec08a95a7ac9c584be0e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task 27 cores benchmark started: Mar 12 2019 20:05:08\n",
      "STARTING K-FOLD CV\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        'num_threads': 27,\n",
    "        'num_leaves': 60,\n",
    "        'min_data_in_leaf': 60,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        'objective': 'binary',\n",
    "        \"metric\": 'auc',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.2,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_seed\": 11,\n",
    "        \"lambda_l1\": 0.1,\n",
    "        \"random_state\": 133,\n",
    "        \"verbosity\": -1\n",
    "}\n",
    "\n",
    "max_iter = 3\n",
    "folds_nr = 3\n",
    "\n",
    "task_name = '27 cores benchmark'\n",
    "\n",
    "folds = KFold(n_splits=folds_nr, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train))\n",
    "categorical_columns = [\n",
    "    c for c in categorical_columns if c not in ['MachineIdentifier']]\n",
    "\n",
    "features = [c for c in train.columns if c not in ['MachineIdentifier']]\n",
    "\n",
    "print(\"task {} started: {}\".format(task_name, time.strftime(\"%b %d %Y %H:%M:%S\")))\n",
    "predictions = np.zeros(len(test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "score = [0 for _ in range(folds.n_splits)]\n",
    "\n",
    "print(\"STARTING K-FOLD CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5d655c2bdc18095817ac18d1f2cf0c09ada07476"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-441a91acc536>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-441a91acc536>\"\u001b[0;36m, line \u001b[0;32m53\u001b[0m\n\u001b[0;31m    cv_score = sum(score) / max_iter\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"task {} starting fold nr {} at: {}\".format(task_name, fold_, time.strftime(\"%b %d %Y %H:%M:%S\")))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_columns\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           categorical_feature=categorical_columns\n",
    "                           )\n",
    "\n",
    "    num_round = 5200\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=200)\n",
    "\n",
    "    oof[val_idx] = clf.predict(\n",
    "        train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(\n",
    "        importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat(\n",
    "        [feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # we perform predictions by chunks\n",
    "    initial_idx = 0\n",
    "    chunk_size = 1000000\n",
    "    current_pred = np.zeros(len(test))\n",
    "    while initial_idx < test.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, test.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = clf.predict(\n",
    "            test.iloc[idx][features], num_iteration=clf.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "    predictions += current_pred / min(folds.n_splits, max_iter)\n",
    "\n",
    "    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    print(\"task {} finished fold nr {} at: {}\".format(task_name, fold_, time.strftime(\"%b %d %Y %H:%M:%S\")))\n",
    "\n",
    "    if fold_ == max_iter - 1:\n",
    "        break\n",
    "\n",
    "print(\"task {} finished 3 FOLDS: {}\".format(task_name, time.strftime(\"%b %d %Y %H:%M:%S\")))        \n",
    "if (folds.n_splits == max_iter):\n",
    "    cv_score = metrics.roc_auc_score(target, oof)\n",
    "else:\n",
    "cv_score = sum(score) / max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c6b43f544acda58e68097906ee9b7eece31a9dc3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d5fb87c7609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_score_printable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:<8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score_printable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv_score_printable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_score_printable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv_score_printable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_score_printable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv_score' is not defined"
     ]
    }
   ],
   "source": [
    "cv_score_printable = \"{:<8.5f}\".format(cv_score)\n",
    "print(\"CV score: {}\".format(cv_score_printable))\n",
    "\n",
    "cv_score_printable = cv_score_printable.replace(\".\", \"\")\n",
    "cv_score_printable = cv_score_printable.strip()\n",
    "\n",
    "\n",
    "# Feature importance\n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[\n",
    "    feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14, 25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    'e{}_lgbm_importances_{}.png'.format(experinment_nr, cv_score_printable))\n",
    "feature_importance_df.to_csv(\n",
    "    'e{}_lgbm_importances_{}.csv'.format(experinment_nr, cv_score_printable))\n",
    "\n",
    "\n",
    "# submit predictions\n",
    "\n",
    "sub_df = pd.read_csv('../input/microsoft-malware-prediction/sample_submission.csv')\n",
    "sub_df[\"HasDetections\"] = predictions\n",
    "\n",
    "model_dir = '../output'\n",
    "\n",
    "\n",
    "model_name = 'submit_e{}_cv{}_{}.csv.gz'.format(\n",
    "    experinment_nr, cv_score_printable, dt.now().strftime('%Y-%m-%d-%H-%M'))\n",
    "\n",
    "fname = os.path.join(model_dir, model_name)\n",
    "param_string = ', '.join(('{}: {}'.format(k, v) for k, v in param.items()))\n",
    "message = 'CV: {} DATA: {} LGBM params: {}'.format(\n",
    "    cv_score_printable, train_fname, param_string)\n",
    "competition = 'microsoft-malware-prediction'\n",
    "\n",
    "sub_df.to_csv(fname, compression='gzip', index=False)\n",
    "#kaggle.api.competition_submit(os.path.abspath(fname), message, competition)\n",
    "print(\"task {} finished: {}\".format(task_name, time.strftime(\"%b %d %Y %H:%M:%S\")))\n",
    "\n",
    "\n",
    "print(\"script finished: \", time.strftime(\"%b %d %Y %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
