{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cf32ed0a9bf164c275e9c7bd3fce38f0f59a3ff"
   },
   "source": [
    "**In this kernel, I try to use Pretrain Bert Model and Feed Forword Network.\n",
    "※I am just starter for deep learning.**\n",
    "**If there are some mistakes, please comment.**\n",
    "\n",
    "1. used code from the kernel below to get word Embedding from pretrain Bert mode.\n",
    "https://www.kaggle.com/mateiionita/taming-the-bert-a-baseline\n",
    "\n",
    "2. Inspired by https://arxiv.org/pdf/1805.04893v1.pdf and https://cs.stanford.edu/people/kevclark/resources/clark-manning-emnlp2016-deep.pdf.\n",
    "I assume that FFNN reduce A, B, Pronoun dimensions(from Bert)  and  only  keep  information relevant to coreference decisions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gendered-pronoun-resolution', 'gap-coreference']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import zipfile\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-19 06:25:29--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 407727028 (389M) [application/zip]\r\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip’\r\n",
      "\r\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M   128MB/s    in 3.0s    \r\n",
      "\r\n",
      "2019-04-19 06:25:32 (128 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\r\n",
      "\r\n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\r\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "!ls 'uncased_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e265e7becd34d793d13009f851a4fc7c6f7f95fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-19 06:25:42--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 37922 (37K) [text/plain]\r\n",
      "Saving to: ‘modeling.py’\r\n",
      "\r\n",
      "modeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2019-04-19 06:25:42 (2.95 MB/s) - ‘modeling.py’ saved [37922/37922]\r\n",
      "\r\n",
      "--2019-04-19 06:25:43--  https://raw.githubusercontent.com/google-research/bert/master/extract_features.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13898 (14K) [text/plain]\r\n",
      "Saving to: ‘extract_features.py’\r\n",
      "\r\n",
      "extract_features.py 100%[===================>]  13.57K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2019-04-19 06:25:43 (1.09 MB/s) - ‘extract_features.py’ saved [13898/13898]\r\n",
      "\r\n",
      "--2019-04-19 06:25:43--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 12257 (12K) [text/plain]\r\n",
      "Saving to: ‘tokenization.py’\r\n",
      "\r\n",
      "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2019-04-19 06:25:43 (64.7 MB/s) - ‘tokenization.py’ saved [12257/12257]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "440d7107d50a014003a2c53485554dc693f81982"
   },
   "outputs": [],
   "source": [
    "import modeling\n",
    "import extract_features\n",
    "import tokenization\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6a15e5f4c32659d3408dee927035725ae0135a39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                        ...                                                                        URL\n",
       "0  development-1                        ...                          http://en.wikipedia.org/wiki/List_of_Teachers_...\n",
       "1  development-2                        ...                              http://en.wikipedia.org/wiki/Warren_MacKenzie\n",
       "2  development-3                        ...                          http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...\n",
       "3  development-4                        ...                                  http://en.wikipedia.org/wiki/Crime_(band)\n",
       "4  development-5                        ...                                http://en.wikipedia.org/wiki/Jessica_Rivera\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df  = pd.read_table('../input/gap-coreference/gap-development.tsv')\n",
    "train_df = pd.read_table('../input/gap-coreference/gap-test.tsv')\n",
    "val_df   = pd.read_table('../input/gap-coreference/gap-validation.tsv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e3d1e4d3037745835e8f34b44a6abea86a85ba7f"
   },
   "outputs": [],
   "source": [
    "#This code is referenced from \n",
    "#https://www.kaggle.com/keyit92/coref-by-mlp-cnn-coattention\n",
    "\n",
    "def bs(lens, target):\n",
    "    low, high = 0, len(lens) - 1\n",
    "\n",
    "    while low < high:\n",
    "        mid = low + int((high - low) / 2)\n",
    "\n",
    "        if target > lens[mid]:\n",
    "            low = mid + 1\n",
    "        elif target < lens[mid]:\n",
    "            high = mid\n",
    "        else:\n",
    "            return mid + 1\n",
    "\n",
    "    return low\n",
    "\n",
    "def bin_distance(dist):\n",
    "    \n",
    "    buckets = [1, 2, 3, 4, 5, 8, 16, 32, 64]  \n",
    "    low, high = 0, len(buckets)\n",
    "    while low < high:\n",
    "        mid = low + int((high-low) / 2)\n",
    "        if dist > buckets[mid]:\n",
    "            low = mid + 1\n",
    "        elif dist < buckets[mid]:\n",
    "            high = mid\n",
    "        else:\n",
    "            return mid\n",
    "\n",
    "    return low\n",
    "\n",
    "def distance_features(P, A, B, char_offsetP, char_offsetA, char_offsetB, text, URL):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    lens = [token.idx for token in doc]\n",
    "    mention_offsetP = bs(lens, char_offsetP) - 1\n",
    "    mention_offsetA = bs(lens, char_offsetA) - 1\n",
    "    mention_offsetB = bs(lens, char_offsetB) - 1\n",
    "    \n",
    "    mention_distA = mention_offsetP - mention_offsetA \n",
    "    mention_distB = mention_offsetP - mention_offsetB\n",
    "    \n",
    "    splited_A = A.split()[0].replace(\"*\", \"\")\n",
    "    splited_B = B.split()[0].replace(\"*\", \"\")\n",
    "    \n",
    "    if re.search(splited_A[0], str(URL)):\n",
    "        contains = 0\n",
    "    elif re.search(splited_B[0], str(URL)):\n",
    "        contains = 1\n",
    "    else:\n",
    "        contains = 2\n",
    "    \n",
    "    dist_binA = bin_distance(mention_distA)\n",
    "    dist_binB = bin_distance(mention_distB)\n",
    "    output =  [dist_binA, dist_binB, contains]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def extract_dist_features(df):\n",
    "    \n",
    "    index = df.index\n",
    "    columns = [\"D_PA\", \"D_PB\", \"IN_URL\"]\n",
    "    dist_df = pd.DataFrame(index = index, columns = columns)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        \n",
    "        text = df.loc[i, 'Text']\n",
    "        P_offset = df.loc[i,'Pronoun-offset']\n",
    "        A_offset = df.loc[i, 'A-offset']\n",
    "        B_offset = df.loc[i, 'B-offset']\n",
    "        P, A, B  = df.loc[i,'Pronoun'], df.loc[i, 'A'], df.loc[i, 'B']\n",
    "        URL = df.loc[i, 'URL']\n",
    "        \n",
    "        dist_df.iloc[i] = distance_features(P, A, B, P_offset, A_offset, B_offset, text, URL)\n",
    "        \n",
    "    return dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "547d5cdb18889257b2f4e460cd06cfeae9bd388b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce8bf79fed94e0898825c24fdeda7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584711139f8042d48df4f2673cd9bfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb52262f0591430cba5bd86579592703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dist_df = extract_dist_features(test_df)\n",
    "test_dist_df.to_csv('test_dist_df.csv', index=False)\n",
    "val_dist_df = extract_dist_features(val_df)\n",
    "val_dist_df.to_csv('val_dist_df.csv', index=False)\n",
    "train_dist_df = extract_dist_features(train_df)\n",
    "train_dist_df.to_csv('train_dist_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "128bf9ecc2123276f55c58cc7f49ed3e2c9eb30b"
   },
   "outputs": [],
   "source": [
    "def count_char(text, offset):   \n",
    "    count = 0\n",
    "    for pos in range(offset):\n",
    "        if text[pos] != \" \": count +=1\n",
    "    return count\n",
    "\n",
    "def candidate_length(candidate):\n",
    "    count = 0\n",
    "    for i in range(len(candidate)):\n",
    "        if candidate[i] !=  \" \": count += 1\n",
    "    return count\n",
    "\n",
    "def count_token_length_special(token):\n",
    "    count = 0\n",
    "    special_token = [\"#\", \" \"]\n",
    "    for i in range(len(token)):\n",
    "        if token[i] not in special_token: count+=1\n",
    "    return count\n",
    "\n",
    "def embed_by_bert(df):\n",
    "    \n",
    "    text = df['Text']\n",
    "    text.to_csv('input.txt', index=False, header=False)\n",
    "    os.system(\"python3 extract_features.py \\\n",
    "               --input_file=input.txt \\\n",
    "               --output_file=output.jsonl \\\n",
    "               --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "               --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "               --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "               --layers=-1 \\\n",
    "               --max_seq_length=256 \\\n",
    "               --batch_size=8\")\n",
    "    \n",
    "    bert_output = pd.read_json(\"output.jsonl\", lines = True)\n",
    "    bert_output.head()\n",
    "    \n",
    "    os.system(\"rm input.txt\")\n",
    "    os.system(\"rm output.jsonl\")\n",
    "    \n",
    "    index = df.index\n",
    "    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
    "    emb = pd.DataFrame(index = index, columns = columns)\n",
    "    emb.index.name = \"ID\"\n",
    "    \n",
    "    for i in tqdm(range(len(text))):\n",
    "        \n",
    "        features = bert_output.loc[i, \"features\"]\n",
    "        P_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'Pronoun-offset'])\n",
    "        A_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'A-offset'])\n",
    "        B_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'B-offset'])\n",
    "        A_length = candidate_length(df.loc[i, 'A'])\n",
    "        B_length = candidate_length(df.loc[i, 'B'])\n",
    "        \n",
    "        emb_A = np.zeros(768)\n",
    "        emb_B = np.zeros(768)\n",
    "        emb_P = np.zeros(768)\n",
    "        \n",
    "        char_count = 0\n",
    "        cnt_A, cnt_B = 0, 0\n",
    "        \n",
    "        for j in range(2, len(features)):\n",
    "            token = features[j][\"token\"]\n",
    "            token_length = count_token_length_special(token)\n",
    "            if char_count == P_char_start:\n",
    "                emb_P += np.asarray(features[j][\"layers\"][0]['values']) \n",
    "            if char_count in range(A_char_start, A_char_start+A_length):\n",
    "                emb_A += np.asarray(features[j][\"layers\"][0]['values'])\n",
    "                cnt_A += 1\n",
    "            if char_count in range(B_char_start, B_char_start+B_length):\n",
    "                emb_B += np.asarray(features[j][\"layers\"][0]['values'])\n",
    "                cnt_B += 1                \n",
    "            char_count += token_length\n",
    "        \n",
    "        emb_A /= cnt_A\n",
    "        emb_B /= cnt_B\n",
    "        \n",
    "        label = \"Neither\"\n",
    "        if (df.loc[i,\"A-coref\"] == True):\n",
    "            label = \"A\"\n",
    "        if (df.loc[i,\"B-coref\"] == True):\n",
    "            label = \"B\"\n",
    "\n",
    "        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n",
    "        \n",
    "    return emb     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "9d2ca43cace4ee9eeea274df5c57ae5f5db04604"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cae85aecec4213a55d007389a98c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c8b0e4ed7741ecb5912bfacf6a5ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8184eee08a4749efaaa0ec00739515a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_emb = embed_by_bert(test_df)\n",
    "test_emb.to_json(\"contextual_embeddings_gap_test.json\", orient = 'columns')\n",
    "validation_emb = embed_by_bert(val_df)\n",
    "validation_emb.to_json(\"contextual_embeddings_gap_validation.json\", orient = 'columns')\n",
    "train_emb = embed_by_bert(train_df)\n",
    "train_emb.to_json(\"contextual_embeddings_gap_train.json\", orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "65d917c5ca0c0e308cf766f700488fcf183f748c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "class End2End_NCR():\n",
    "    \n",
    "    def __init__(self, word_input_shape, dist_shape, embed_dim=20): \n",
    "        \n",
    "        self.word_input_shape = word_input_shape\n",
    "        self.dist_shape   = dist_shape\n",
    "        self.embed_dim    = embed_dim\n",
    "        self.buckets      = [1, 2, 3, 4, 5, 8, 16, 32, 64] \n",
    "        self.hidden_dim   = 150\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        A, B, P = Input((self.word_input_shape,)), Input((self.word_input_shape,)), Input((self.word_input_shape,))\n",
    "        dist1, dist2 = Input((self.dist_shape,)), Input((self.dist_shape,))\n",
    "        inputs = [A, B, P]\n",
    "        dist_inputs = [dist1, dist2]\n",
    "        \n",
    "        self.dist_embed = Embedding(len(self.buckets)+1, self.embed_dim)\n",
    "        self.ffnn       = Sequential([Dense(self.hidden_dim, use_bias=True),\n",
    "                                     Activation('relu'),\n",
    "                                     Dropout(rate=0.2, seed = 7),\n",
    "                                     Dense(1, activation='linear')])\n",
    "        \n",
    "        dist_embeds = [self.dist_embed(dist) for dist in dist_inputs]\n",
    "        dist_embeds = [Flatten()(dist_embed) for dist_embed in dist_embeds]\n",
    "        \n",
    "        #Scoring layer\n",
    "        #In https://www.aclweb.org/anthology/D17-1018, \n",
    "        #used feed forward network which measures if it is an entity mention using a score\n",
    "        #because we already know the word is mention.\n",
    "        #In here, I just focus on the pairwise score\n",
    "        PA = Multiply()([inputs[0], inputs[2]])\n",
    "        PB = Multiply()([inputs[1], inputs[2]])\n",
    "        #PairScore: sa(i,j) =wa·FFNNa([gi,gj,gi◦gj,φ(i,j)])\n",
    "        # gi is embedding of Pronoun\n",
    "        # gj is embedding of A or B\n",
    "        # gi◦gj is element-wise multiplication\n",
    "        # φ(i,j) is the distance embedding\n",
    "        PA = Concatenate(axis=-1)([P, A, PA, dist_embeds[0]])\n",
    "        PB = Concatenate(axis=-1)([P, B, PB, dist_embeds[1]])\n",
    "        PA_score = self.ffnn(PA)\n",
    "        PB_score = self.ffnn(PB)\n",
    "        # Fix the Neither to score 0.\n",
    "        score_e  = Lambda(lambda x: K.zeros_like(x))(PB_score)\n",
    "        \n",
    "        #Final Output\n",
    "        output = Concatenate(axis=-1)([PA_score, PB_score, score_e]) # [Pronoun and A score, Pronoun and B score, Neither Score]\n",
    "        output = Activation('softmax')(output)        \n",
    "        model = Model(inputs+dist_inputs, output)\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "78ad73eabc65583a927c7f2ac721aa4551ae0992"
   },
   "outputs": [],
   "source": [
    "def create_input(embed_df, dist_df):\n",
    "    \n",
    "    assert len(embed_df) == len(dist_df)\n",
    "    all_P, all_A, all_B = [] ,[] ,[]\n",
    "    all_label = []\n",
    "    all_dist_PA, all_dist_PB = [], []\n",
    "    url_A, url_B = [], []\n",
    "    \n",
    "    for i in tqdm(range(len(embed_df))):\n",
    "        \n",
    "        all_P.append(embed_df.loc[i, \"emb_P\"])\n",
    "        all_A.append(embed_df.loc[i, \"emb_A\"])\n",
    "        all_B.append(embed_df.loc[i, \"emb_B\"])\n",
    "        all_dist_PA.append(dist_df.loc[i, \"D_PA\"])\n",
    "        all_dist_PB.append(dist_df.loc[i, \"D_PB\"])\n",
    "        \n",
    "        if dist_df.loc[i, \"IN_URL\"] == 0:\n",
    "            url_A.append(1)\n",
    "            url_B.append(0)\n",
    "        elif dist_df.loc[i, \"IN_URL\"] == 1:\n",
    "            url_A.append(0)\n",
    "            url_B.append(1)\n",
    "        else:\n",
    "            url_A.append(0)\n",
    "            url_B.append(0)\n",
    "        \n",
    "        label = embed_df.loc[i, \"label\"]\n",
    "        if label == \"A\": \n",
    "            all_label.append(0)\n",
    "        elif label == \"B\": \n",
    "            all_label.append(1)\n",
    "        else: \n",
    "            all_label.append(2)\n",
    "    \n",
    "    return [np.asarray(all_A), np.asarray(all_B), np.asarray(all_P),\n",
    "            np.expand_dims(np.asarray(all_dist_PA),axis=1),\n",
    "            np.expand_dims(np.asarray(all_dist_PB),axis=1)],all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "78cb5a82884acc0592330f65ac2df5e40408a747"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_A</th>\n",
       "      <th>emb_B</th>\n",
       "      <th>emb_P</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.14526466666666668, -0.36192699999999994, 0...</td>\n",
       "      <td>[-0.47775049999999997, -0.598545, 0.426645, 0....</td>\n",
       "      <td>[-0.551684, -0.023438, -0.549022, -0.159332, 0...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.043327, 0.055112999999999995, 0.48952799999...</td>\n",
       "      <td>[0.02212816666666667, -0.43065516666666664, 0....</td>\n",
       "      <td>[0.06615499999999999, -0.050293, -0.173699, 0....</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.09385075000000001, 0.701532, 0.18457674999...</td>\n",
       "      <td>[0.227958, 0.531238, -0.43523599999999996, -0....</td>\n",
       "      <td>[-0.266816, 0.18423899999999999, -0.149993, -0...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.8687406666666666, -0.04495166666666665, 0....</td>\n",
       "      <td>[-0.381581, -0.103236, 0.6846015000000001, 0.0...</td>\n",
       "      <td>[0.100225, -0.19070199999999998, -0.4836149999...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.327636, -0.043740999999999995, 0.470923, 0....</td>\n",
       "      <td>[-0.5405355000000001, -0.7521034999999999, -0....</td>\n",
       "      <td>[-0.541744, 0.6634639999999999, 0.291974, 0.06...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               emb_A  ...  label\n",
       "0  [-0.14526466666666668, -0.36192699999999994, 0...  ...      B\n",
       "1  [0.043327, 0.055112999999999995, 0.48952799999...  ...      A\n",
       "2  [-0.09385075000000001, 0.701532, 0.18457674999...  ...      A\n",
       "3  [-0.8687406666666666, -0.04495166666666665, 0....  ...      B\n",
       "4  [0.327636, -0.043740999999999995, 0.470923, 0....  ...      A\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emb_df = pd.concat([train_emb, validation_emb])\n",
    "new_emb_df = new_emb_df.reset_index(drop=True)\n",
    "new_dist_df = pd.concat([train_dist_df, val_dist_df])\n",
    "new_dist_df = new_dist_df.reset_index(drop=True)\n",
    "\n",
    "new_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9eecf8cbabf3ebd4e98ba5c80c00b6681a0b4943"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e570aaf95c634313bd14c55af3fcf2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e951521ab404301b7fe0df2fd128eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_input(new_emb_df, new_dist_df)\n",
    "X_test, y_test = create_input(test_emb, test_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "4bb874eb34b26635fbe65bc271a0acda9f9af237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 20)        200         input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 768)          0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 768)          0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 20)           0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2324)         0           input_3[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 multiply_1[0][0]                 \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2324)         0           input_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 multiply_2[0][0]                 \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            348901      concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 3)            0           concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 349,101\n",
      "Trainable params: 349,101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = End2End_NCR(word_input_shape=X_train[0].shape[1], dist_shape=X_train[3].shape[1]).build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "73812eb91330412324d1da9eb641f672e43e0a59"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 712.00 556.00\" width=\"712pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 708,-552 708,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139976995775152 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139976995775152</title>\n",
       "<polygon fill=\"none\" points=\"151,-511.5 151,-547.5 276,-547.5 276,-511.5 151,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-525.8\">input_4: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139976995775096 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139976995775096</title>\n",
       "<polygon fill=\"none\" points=\"204,-438.5 204,-474.5 365,-474.5 365,-438.5 204,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-452.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 139976995775152&#45;&gt;139976995775096 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139976995775152-&gt;139976995775096</title>\n",
       "<path d=\"M230.687,-511.313C239.583,-502.417 250.591,-491.409 260.328,-481.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.875,-484.075 267.471,-474.529 257.925,-479.125 262.875,-484.075\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976995775376 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139976995775376</title>\n",
       "<polygon fill=\"none\" points=\"294,-511.5 294,-547.5 419,-547.5 419,-511.5 294,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"356.5\" y=\"-525.8\">input_5: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139976995775376&#45;&gt;139976995775096 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139976995775376-&gt;139976995775096</title>\n",
       "<path d=\"M339.071,-511.313C330.05,-502.417 318.887,-491.409 309.012,-481.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"311.347,-479.058 301.769,-474.529 306.432,-484.042 311.347,-479.058\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986684463368 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139986684463368</title>\n",
       "<polygon fill=\"none\" points=\"414,-438.5 414,-474.5 539,-474.5 539,-438.5 414,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-452.8\">input_3: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139970573368960 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139970573368960</title>\n",
       "<polygon fill=\"none\" points=\"188.5,-365.5 188.5,-401.5 320.5,-401.5 320.5,-365.5 188.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.5\" y=\"-379.8\">multiply_1: Multiply</text>\n",
       "</g>\n",
       "<!-- 139986684463368&#45;&gt;139970573368960 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139986684463368-&gt;139970573368960</title>\n",
       "<path d=\"M423.325,-438.494C391.569,-428.338 351.053,-415.379 317.672,-404.704\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"318.601,-401.326 308.01,-401.614 316.469,-407.994 318.601,-401.326\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573366216 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139970573366216</title>\n",
       "<polygon fill=\"none\" points=\"504.5,-365.5 504.5,-401.5 636.5,-401.5 636.5,-365.5 504.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"570.5\" y=\"-379.8\">multiply_2: Multiply</text>\n",
       "</g>\n",
       "<!-- 139986684463368&#45;&gt;139970573366216 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139986684463368-&gt;139970573366216</title>\n",
       "<path d=\"M499.255,-438.313C511.378,-429.156 526.466,-417.76 539.631,-407.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"542.085,-410.349 547.955,-401.529 537.866,-404.763 542.085,-410.349\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573366104 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139970573366104</title>\n",
       "<polygon fill=\"none\" points=\"170.5,-292.5 170.5,-328.5 338.5,-328.5 338.5,-292.5 170.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.5\" y=\"-306.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139986684463368&#45;&gt;139970573366104 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139986684463368-&gt;139970573366104</title>\n",
       "<path d=\"M480.847,-438.33C483.703,-423.218 485.451,-401.1 476.5,-384.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M476.5,-382.5C463.618,-358.61 403.275,-340.261 348.751,-328.206\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"349.163,-324.715 338.65,-326.029 347.688,-331.558 349.163,-324.715\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573366048 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139970573366048</title>\n",
       "<polygon fill=\"none\" points=\"392.5,-292.5 392.5,-328.5 560.5,-328.5 560.5,-292.5 392.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-306.8\">concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139986684463368&#45;&gt;139970573366048 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>139986684463368-&gt;139970573366048</title>\n",
       "<path d=\"M476.5,-382.5C469.367,-369.272 469.028,-352.54 470.63,-338.641\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"474.103,-339.084 472.153,-328.67 467.183,-338.027 474.103,-339.084\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986684462416 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139986684462416</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 125,-474.5 125,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-452.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139986684462416&#45;&gt;139970573368960 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139986684462416-&gt;139970573368960</title>\n",
       "<path d=\"M108.489,-438.494C135.6,-428.468 170.094,-415.713 198.747,-405.117\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"200.056,-408.365 208.221,-401.614 197.628,-401.799 200.056,-408.365\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986684462416&#45;&gt;139970573366104 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139986684462416-&gt;139970573366104</title>\n",
       "<path d=\"M53.7407,-438.237C45.0789,-418.455 35.2696,-386.062 51.5,-365 65.3863,-346.98 114.004,-333.812 160.177,-325.05\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"161.084,-328.442 170.287,-323.192 159.819,-321.557 161.084,-328.442\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573369296 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139970573369296</title>\n",
       "<polygon fill=\"none\" points=\"60.5,-365.5 60.5,-401.5 170.5,-401.5 170.5,-365.5 60.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115.5\" y=\"-379.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 139976995775096&#45;&gt;139970573369296 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139976995775096-&gt;139970573369296</title>\n",
       "<path d=\"M244.02,-438.494C220.468,-428.599 190.586,-416.045 165.564,-405.533\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.81,-402.26 156.235,-401.614 164.099,-408.714 166.81,-402.26\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573367000 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139970573367000</title>\n",
       "<polygon fill=\"none\" points=\"338.5,-365.5 338.5,-401.5 448.5,-401.5 448.5,-365.5 338.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393.5\" y=\"-379.8\">flatten_2: Flatten</text>\n",
       "</g>\n",
       "<!-- 139976995775096&#45;&gt;139970573367000 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139976995775096-&gt;139970573367000</title>\n",
       "<path d=\"M310.608,-438.494C325.063,-429.079 343.213,-417.255 358.843,-407.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"360.758,-410.004 367.227,-401.614 356.938,-404.139 360.758,-410.004\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986684463984 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139986684463984</title>\n",
       "<polygon fill=\"none\" points=\"579,-438.5 579,-474.5 704,-474.5 704,-438.5 579,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"641.5\" y=\"-452.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139986684463984&#45;&gt;139970573366216 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139986684463984-&gt;139970573366216</title>\n",
       "<path d=\"M624.313,-438.313C615.417,-429.417 604.409,-418.409 594.672,-408.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"597.075,-406.125 587.529,-401.529 592.125,-411.075 597.075,-406.125\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986684463984&#45;&gt;139970573366048 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>139986684463984-&gt;139970573366048</title>\n",
       "<path d=\"M648.127,-438.327C654.51,-418.63 661.111,-386.317 645.5,-365 627.775,-340.796 599.044,-327.268 570.26,-319.795\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"571.049,-316.385 560.512,-317.486 569.436,-323.197 571.049,-316.385\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573368960&#45;&gt;139970573366104 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139970573368960-&gt;139970573366104</title>\n",
       "<path d=\"M254.5,-365.313C254.5,-357.289 254.5,-347.547 254.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258,-338.529 254.5,-328.529 251,-338.529 258,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573369296&#45;&gt;139970573366104 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139970573369296-&gt;139970573366104</title>\n",
       "<path d=\"M148.794,-365.494C167.739,-355.817 191.663,-343.597 211.958,-333.23\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.683,-336.279 220.996,-328.614 210.498,-330.046 213.683,-336.279\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573366216&#45;&gt;139970573366048 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>139970573366216-&gt;139970573366048</title>\n",
       "<path d=\"M547.745,-365.313C535.622,-356.156 520.534,-344.76 507.369,-334.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"509.134,-331.763 499.045,-328.529 504.915,-337.349 509.134,-331.763\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573367000&#45;&gt;139970573366048 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>139970573367000-&gt;139970573366048</title>\n",
       "<path d=\"M413.592,-365.313C424.195,-356.243 437.365,-344.977 448.911,-335.1\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"451.269,-337.689 456.593,-328.529 446.719,-332.37 451.269,-337.689\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573365320 -->\n",
       "<g class=\"node\" id=\"node13\"><title>139970573365320</title>\n",
       "<polygon fill=\"none\" points=\"291,-219.5 291,-255.5 440,-255.5 440,-219.5 291,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-233.8\">sequential_1: Sequential</text>\n",
       "</g>\n",
       "<!-- 139970573366104&#45;&gt;139970573365320 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>139970573366104-&gt;139970573365320</title>\n",
       "<path d=\"M281.087,-292.494C295.807,-283.079 314.291,-271.255 330.207,-261.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"332.207,-263.95 338.745,-255.614 328.435,-258.054 332.207,-263.95\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139970573366048&#45;&gt;139970573365320 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>139970573366048-&gt;139970573365320</title>\n",
       "<path d=\"M449.913,-292.494C435.193,-283.079 416.709,-271.255 400.793,-261.075\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"402.565,-258.054 392.255,-255.614 398.793,-263.95 402.565,-258.054\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139982604143640 -->\n",
       "<g class=\"node\" id=\"node14\"><title>139982604143640</title>\n",
       "<polygon fill=\"none\" points=\"349,-146.5 349,-182.5 472,-182.5 472,-146.5 349,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"410.5\" y=\"-160.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139970573365320&#45;&gt;139982604143640 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>139970573365320-&gt;139982604143640</title>\n",
       "<path d=\"M376.393,-219.313C381.755,-210.853 388.327,-200.484 394.267,-191.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"397.31,-192.849 399.707,-182.529 391.397,-189.102 397.31,-192.849\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139982639136952 -->\n",
       "<g class=\"node\" id=\"node15\"><title>139982639136952</title>\n",
       "<polygon fill=\"none\" points=\"281.5,-73.5 281.5,-109.5 449.5,-109.5 449.5,-73.5 281.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-87.8\">concatenate_3: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139970573365320&#45;&gt;139982639136952 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>139970573365320-&gt;139982639136952</title>\n",
       "<path d=\"M354.723,-219.411C348.964,-209.257 342.464,-195.882 339.5,-183 335.812,-166.974 335.812,-162.026 339.5,-146 341.654,-136.641 345.674,-127.021 349.92,-118.565\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"353.092,-120.057 354.723,-109.589 346.919,-116.755 353.092,-120.057\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139982604143640&#45;&gt;139982639136952 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>139982604143640-&gt;139982639136952</title>\n",
       "<path d=\"M399.607,-146.313C394.245,-137.853 387.673,-127.484 381.733,-118.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"384.603,-116.102 376.293,-109.529 378.69,-119.849 384.603,-116.102\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139986670947632 -->\n",
       "<g class=\"node\" id=\"node16\"><title>139986670947632</title>\n",
       "<polygon fill=\"none\" points=\"291.5,-0.5 291.5,-36.5 439.5,-36.5 439.5,-0.5 291.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-14.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 139982639136952&#45;&gt;139986670947632 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>139982639136952-&gt;139986670947632</title>\n",
       "<path d=\"M365.5,-73.3129C365.5,-65.2895 365.5,-55.5475 365.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"369,-46.5288 365.5,-36.5288 362,-46.5289 369,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "727130aaa44085dec2282398e86762c818d1ae57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "min_loss = 1.0\n",
    "best_model = 0\n",
    "# Use Kfold to get best model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "n_fold = 5\n",
    "kfold = KFold(n_splits=n_fold, shuffle=True, random_state=3)\n",
    "for fold_n, (train_index, valid_index) in enumerate(kfold.split(X_train[0])):\n",
    "    \n",
    "    X_tr  = [inputs[train_index] for inputs in X_train]\n",
    "    X_val = [inputs[valid_index] for inputs in X_train]\n",
    "    y_tr  = np.asarray(y_train)[train_index]\n",
    "    y_val = np.asarray(y_train)[valid_index]\n",
    "    \n",
    "    model = End2End_NCR(word_input_shape=X_train[0].shape[1], dist_shape=X_train[3].shape[1]).build()\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss=\"sparse_categorical_crossentropy\")\n",
    "    file_path = \"best_model_{}.hdf5\".format(fold_n+1)\n",
    "    check_point = callbacks.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 0, save_best_only = True, mode = \"min\")\n",
    "    early_stop = callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=100)\n",
    "    hist = model.fit(X_tr, y_tr, batch_size=128, epochs=1000, validation_data=(X_val, y_val), verbose=0,\n",
    "              shuffle=True, callbacks = [check_point, early_stop])\n",
    "    \n",
    "    if min(hist.history['val_loss']) < min_loss:\n",
    "        min_loss = min(hist.history['val_loss'])\n",
    "        best_model = fold_n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "7fac0215cd009f4b1a9af60b0f795606a9924ab8"
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "6f16dbf78d029c6840415e69021a242bddfd3695",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000075809a8e6b062f5fb3c191a8ed52</td>\n",
       "      <td>0.836955</td>\n",
       "      <td>0.120751</td>\n",
       "      <td>0.042294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005d0f3b0a6c9ffbd31a48453029911</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.005767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007775c40bedd4147a0573d66dc28f8</td>\n",
       "      <td>0.043715</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>0.030781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001194e3fe1234d00198ef6bba4cc588</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.733608</td>\n",
       "      <td>0.240065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014bb7085278ef3f9b74f14771caca9</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002671a4f3ec8d724e0541c2f1a1f8cc</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002eb2ad27bbeab286b15650b8cb2c27</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>0.044514</td>\n",
       "      <td>0.580886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002eebd91abbd53207da15ae61714531</td>\n",
       "      <td>0.330328</td>\n",
       "      <td>0.596830</td>\n",
       "      <td>0.072842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0034d8a107da2eeba335128665f6fc1f</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0034dfd350220409b621a5e3ac1c5e02</td>\n",
       "      <td>0.773379</td>\n",
       "      <td>0.194037</td>\n",
       "      <td>0.032584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0038594ac3031cfe28506b2356a164f0</td>\n",
       "      <td>0.069562</td>\n",
       "      <td>0.603726</td>\n",
       "      <td>0.326713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>003c6dedd37fd9e61fe7d4caeeb6cce2</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>0.090393</td>\n",
       "      <td>0.029490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>003d42668ef51e38ef23747e0e63ae2a</td>\n",
       "      <td>0.631580</td>\n",
       "      <td>0.356045</td>\n",
       "      <td>0.012375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004d34d0538140b06c9fb8a5a79be949</td>\n",
       "      <td>0.659291</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>0.081695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>004e46b35db66402fa8046fd7bd800fb</td>\n",
       "      <td>0.231365</td>\n",
       "      <td>0.639783</td>\n",
       "      <td>0.128852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0053b6a829b09c988164aaec0ee2fb4b</td>\n",
       "      <td>0.054615</td>\n",
       "      <td>0.761045</td>\n",
       "      <td>0.184340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0056e846c6c6a948326fac4caebac70d</td>\n",
       "      <td>0.589012</td>\n",
       "      <td>0.382722</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00587d0e442b7b4521f685d12f8b78d3</td>\n",
       "      <td>0.478533</td>\n",
       "      <td>0.455804</td>\n",
       "      <td>0.065663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>006506c9485f14a3d850b2c7dc06d28c</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>0.921375</td>\n",
       "      <td>0.054788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00666e20548dc00c0506444b39522d1c</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.195501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID         A         B   NEITHER\n",
       "0   000075809a8e6b062f5fb3c191a8ed52  0.836955  0.120751  0.042294\n",
       "1   0005d0f3b0a6c9ffbd31a48453029911  0.993733  0.000500  0.005767\n",
       "2   0007775c40bedd4147a0573d66dc28f8  0.043715  0.925504  0.030781\n",
       "3   001194e3fe1234d00198ef6bba4cc588  0.026327  0.733608  0.240065\n",
       "4   0014bb7085278ef3f9b74f14771caca9  0.000168  0.999469  0.000363\n",
       "5   002671a4f3ec8d724e0541c2f1a1f8cc  0.997507  0.001682  0.000811\n",
       "6   002eb2ad27bbeab286b15650b8cb2c27  0.374600  0.044514  0.580886\n",
       "7   002eebd91abbd53207da15ae61714531  0.330328  0.596830  0.072842\n",
       "8   0034d8a107da2eeba335128665f6fc1f  0.000079  0.999391  0.000530\n",
       "9   0034dfd350220409b621a5e3ac1c5e02  0.773379  0.194037  0.032584\n",
       "10  0038594ac3031cfe28506b2356a164f0  0.069562  0.603726  0.326713\n",
       "11  003c6dedd37fd9e61fe7d4caeeb6cce2  0.880117  0.090393  0.029490\n",
       "12  003d42668ef51e38ef23747e0e63ae2a  0.631580  0.356045  0.012375\n",
       "13  004d34d0538140b06c9fb8a5a79be949  0.659291  0.259013  0.081695\n",
       "14  004e46b35db66402fa8046fd7bd800fb  0.231365  0.639783  0.128852\n",
       "15  0053b6a829b09c988164aaec0ee2fb4b  0.054615  0.761045  0.184340\n",
       "16  0056e846c6c6a948326fac4caebac70d  0.589012  0.382722  0.028266\n",
       "17  00587d0e442b7b4521f685d12f8b78d3  0.478533  0.455804  0.065663\n",
       "18  006506c9485f14a3d850b2c7dc06d28c  0.023837  0.921375  0.054788\n",
       "19  00666e20548dc00c0506444b39522d1c  0.003295  0.801205  0.195501"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use best model to predict\n",
    "model = End2End_NCR(word_input_shape=X_train[0].shape[1], dist_shape=X_train[3].shape[1]).build()\n",
    "model.load_weights(\"./best_model_{}.hdf5\".format(best_model))\n",
    "pred = model.predict(x = X_test, verbose = 0)\n",
    "\n",
    "sub_df_path = os.path.join('../input/gendered-pronoun-resolution/', 'sample_submission_stage_2.csv')\n",
    "sub_df = pd.read_csv(sub_df_path)\n",
    "sub_df.loc[:, 'A'] = pd.Series(pred[:, 0])\n",
    "sub_df.loc[:, 'B'] = pd.Series(pred[:, 1])\n",
    "sub_df.loc[:, 'NEITHER'] = pd.Series(pred[:, 2])\n",
    "\n",
    "sub_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "6b95c352c3847f2adeaf8153b4eaa46fab958096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4838068183946834"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "y_one_hot = np.zeros((2000, 3))\n",
    "for i in range(len(y_test)):\n",
    "    y_one_hot[i, y_test[i]] = 1\n",
    "log_loss(y_one_hot, pred) # Calculate the log loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "d17c4e194ecfd465f20b465effe3b7a33038a6dc"
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
