{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./kfold_model.pkl', 'rb') as f:\n",
    "    kfold_lgb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold_result = kfold_lgb.kfold_result_\n",
    "for n_fold in kfold_result.keys():\n",
    "    fold_res = kfold_result[n_fold]\n",
    "    print(n_fold)\n",
    "    print(\"%-30s %d\" % ('BEST_ITER:', fold_res['best_iteration']))\n",
    "    print(\"%-30s %.6f\" % ('BEST_SCORE_TRAIN:', fold_res['best_score']['training']))\n",
    "    print(\"%-30s %.6f\" % ('BEST_SCORE_VALID:', fold_res['best_score']['valid']))\n",
    "    print(\"%-30s %d\" % ('TRAINING_USING_TIME:', fold_res['using_time']))\n",
    "    print(\"=\"* 50)\n",
    "print(\"%-30s %.6f\" % ('FULL AUC:', kfold_lgb.score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> EVAL RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 28))\n",
    "fold_nums = len(kfold_result)\n",
    "for n_fold, fold_res in kfold_result.items():\n",
    "    df = pd.DataFrame(fold_res['evals_result'])\n",
    "    df.plot(kind='line', figsize=(8, 6), fontsize=12)\n",
    "    plt.title('eval result in fold %s' % n_fold)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "for n_fold, fold_result in kfold_result.items():\n",
    "    feature_importance_df[n_fold] = fold_result['feature_importance']\n",
    "feature_importance_df.index = kfold_lgb.features_\n",
    "feature_importance_df['mean'] = feature_importance_df.mean(axis=1)\n",
    "feature_importance_df['std'] = feature_importance_df.std(axis=1)\n",
    "feature_importance_df['rank'] = feature_importance_df['mean'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance_df.sort_values(by='mean', ascending=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    plt.figure(figsize=(12, 28))\n",
    "    top100 = feature_importance_df_.sort_values(by='mean', ascending=False)[['mean', 'std']][: 100]\n",
    "    top100['mean'].plot(kind='barh', xerr=top100['std'])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "display_importances(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font size=5> DETAILED Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(name):\n",
    "    lst = []\n",
    "    feats_len = len(feature_importance_df)\n",
    "    for col in feature_importance_df.index:\n",
    "        if name in col:\n",
    "            lst.append(col)\n",
    "    \n",
    "    print('    %s     %-90s %s' % ('RANK', 'FEATURE NAME', 'IMPORTANCE'))\n",
    "    print('='* 115)\n",
    "    for feat in lst:\n",
    "        s = '%4d/%s    %-90s %.2f' % (feature_importance_df.loc[feat, 'rank'], feats_len, feat, feature_importance_df.loc[feat, 'mean'])\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = feature_importance_df.sort_values(by='mean', ascending=False)\n",
    "print('    %s     %-90s %s' % ('RANK', 'FEATURE NAME', 'IMPORTANCE'))\n",
    "print('='* 115)\n",
    "feats_len = len(df)\n",
    "for i, feat in enumerate(df.index, start=1):\n",
    "    s = '%4d/%s    %-90s %.2f' % (i, feats_len, feat, df.loc[feat, 'mean'])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in feature_importance_df.index:\n",
    "    if feature_importance_df.loc[col, 'mean'] <= 1:\n",
    "        print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
