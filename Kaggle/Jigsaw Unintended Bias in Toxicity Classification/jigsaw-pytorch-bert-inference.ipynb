{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Jigsaw Unintended Bias in Toxicity Classification\n",
    "\n",
    "Inference only. This notebook runs on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.6\n",
      "PyTorch version: 1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f'Python version: {platform.python_version()}')\n",
    "print(f'PyTorch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook runs on GPU\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "assert NUM_GPUS > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define flags**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def define_args(str_list):\n",
    "    '''\n",
    "      A lite version of args at https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py#L565\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    ## Required parameters\n",
    "    parser.add_argument(\"--data_dir\",\n",
    "                        default=None,\n",
    "                        type=str,\n",
    "                        required=True,\n",
    "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    parser.add_argument(\"--model_dir\",\n",
    "                        default=None,\n",
    "                        type=str,\n",
    "                        required=True,\n",
    "                        help=\"The model directory.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    parser.add_argument(\"--max_seq_length\",\n",
    "                        default=None,\n",
    "                        type=int,\n",
    "                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "                             \"than this will be padded.\")\n",
    "    parser.add_argument(\"--do_lower_case\",\n",
    "                        action='store_true',\n",
    "                        help=\"Set this flag if you are using an uncased model.\")\n",
    "    parser.add_argument(\"--eval_batch_size\",\n",
    "                        default=8,\n",
    "                        type=int,\n",
    "                        help=\"Total batch size for eval.\")\n",
    "\n",
    "    args = parser.parse_args(str_list)\n",
    "    args.do_lower_case = 'uncased' in args.model_dir\n",
    "\n",
    "    m = re.search(r'^.+cased-len-(\\d+)-fp(16|32)\\/epoch-\\d+$', args.model_dir)\n",
    "    args.max_seq_length = int(m.group(1))\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='../input/jigsaw-unintended-bias-in-toxicity-classification', do_lower_case=True, eval_batch_size=8, max_seq_length=220, model_dir='../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-large-uncased-len-220-fp16/epoch-1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = define_args([\n",
    "    '--data_dir', '../input/jigsaw-unintended-bias-in-toxicity-classification',\n",
    "    '--model_dir', '../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-large-uncased-len-220-fp16/epoch-1',\n",
    "])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(args.model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pytorch-pretrained-bert ...\n",
      "Installed pytorch-pretrained-bert successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "except ModuleNotFoundError:\n",
    "    print('Installing pytorch-pretrained-bert ...')\n",
    "    if 'KAGGLE_URL_BASE' in os.environ:  # kaggle kernel\n",
    "        bert_lib = '../input/pytorchpretrainedbert/pytorch-pretrained-bert-master/pytorch-pretrained-BERT-master'\n",
    "        assert os.path.exists(bert_lib)\n",
    "        sys.path.insert(0, bert_lib)\n",
    "    else:\n",
    "        print(subprocess.check_output('sudo -u jupyter conda install -y -c conda-forge pytorch-pretrained-bert', shell=True).decode('utf-8'))\n",
    "    print('Installed pytorch-pretrained-bert successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns=['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file ../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-large-uncased-len-220-fp16/epoch-1/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.model_dir, do_lower_case=args.do_lower_case, cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines(lines, max_seq_length, tokenizer):\n",
    "    '''\n",
    "      Converting the lines to BERT format.\n",
    "      \n",
    "      Copied from https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\n",
    "    '''\n",
    "    max_seq_length -= 2  # CLS, SEP\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(lines):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            tokens_a = tokens_a[:max_seq_length]\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "        all_tokens.append(one_token)\n",
    "    print(f'longer: {longer}')\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(args.data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all comment_text values are strings\n",
    "test_df['comment_text'] = test_df['comment_text'].astype(str).fillna(\"DUMMY_VALUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2db38876b94a13850754b4e3691fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=97320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "longer: 2191\n"
     ]
    }
   ],
   "source": [
    "X_test = convert_lines(test_df[\"comment_text\"], args.max_seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 220)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_model(model_dir):\n",
    "    # Load a trained model and vocabulary that you have fine-tuned\n",
    "    model = BertForSequenceClassification.from_pretrained(model_dir, num_labels=len(y_columns), cache_dir=None)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, valid_dataset):\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.eval_batch_size, shuffle=False)\n",
    "    batch_size=args.eval_batch_size\n",
    "    valid_preds = np.zeros((len(valid_dataset)))\n",
    "    \n",
    "    for step, (x_batch, ) in tqdm_notebook(enumerate(valid_loader), total=len(valid_loader)):\n",
    "        y_pred = model(x_batch.to(DEVICE), attention_mask=(x_batch>0).to(DEVICE), labels=None)\n",
    "        valid_preds[step*batch_size:(step+1)*batch_size]=y_pred[:,0].detach().cpu().squeeze().numpy()\n",
    "    return valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file ../input/bert-fine-tuned-for-jigsaw/jigsaw-bert-large-uncased-len-220-fp16/epoch-1\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_eval_model(args.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d096b3d8d4c481a873bb6a255bb5b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12165), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = predict(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97320,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = torch.sigmoid(torch.tensor(y_test)).numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97320,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_df['id'],\n",
    "    'prediction': test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.999096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0  7000000    0.000077\n",
       "1  7000001    0.000049\n",
       "2  7000002    0.000447\n",
       "3  7000003    0.000083\n",
       "4  7000004    0.999096"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
