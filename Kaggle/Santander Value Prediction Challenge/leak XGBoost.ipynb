{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "caa44bc10a9d34d96916eba5a4f90dba73e84735"
   },
   "source": [
    "I've used the results found in : https://www.kaggle.com/johnfarrell/breaking-lb-fresh-start-with-lag-selection/output and\n",
    "https://www.kaggle.com/ogrellier/feature-scoring-vs-zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e9fddf207ae05e8c1d0e76ce43f12df6252acee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_csv('../input/santander-value-prediction-challenge/train.csv')\n",
    "target = np.log1p(data['target'])\n",
    "data.drop(['ID', 'target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "632e6a2563936127c06287cfc3a1cf309385934e"
   },
   "source": [
    "### Add train leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "leak = pd.read_csv('../input/breaking-lb-fresh-start-with-lag-selection/train_leak.csv')\n",
    "data['leak'] = leak['compiled_leak'].values\n",
    "data['log_leak'] = np.log1p(leak['compiled_leak'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c8610c5187001d7ec17a7ffaf203859c6f9aa46"
   },
   "source": [
    "### Feature Scoring using XGBoost with the leak feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68e309e111e4a772a6ec4d8cf00c11e134c23f05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** .5\n",
    "\n",
    "reg = XGBRegressor(n_estimators=1000)\n",
    "folds = KFold(4, True, 134259)\n",
    "fold_idx = [(trn_, val_) for trn_, val_ in folds.split(data)]\n",
    "scores = []\n",
    "\n",
    "nb_values = data.nunique(dropna=False)\n",
    "nb_zeros = (data == 0).astype(np.uint8).sum(axis=0)\n",
    "\n",
    "features = [f for f in data.columns if f not in ['log_leak', 'leak', 'target', 'ID']]\n",
    "for _f in features:\n",
    "    score = 0\n",
    "    for trn_, val_ in fold_idx:\n",
    "        reg.fit(\n",
    "            data[['log_leak', _f]].iloc[trn_], target.iloc[trn_],\n",
    "            eval_set=[(data[['log_leak', _f]].iloc[val_], target.iloc[val_])],\n",
    "            eval_metric='rmse',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        score += rmse(target.iloc[val_], reg.predict(data[['log_leak', _f]].iloc[val_], ntree_limit=reg.best_ntree_limit)) / folds.n_splits\n",
    "    scores.append((_f, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3694822b9bc81bb6896f417cee646e1990577917"
   },
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7863f32d4b51d6dc957453365d8e79682848f4e4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame(scores, columns=['feature', 'rmse']).set_index('feature')\n",
    "report['nb_zeros'] = nb_zeros\n",
    "report['nunique'] = nb_values\n",
    "report.sort_values(by='rmse', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4db7b58fc5b7dc4acb58b0b23a3e05f46dc612e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report.to_csv('feature_report.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0036802c721bc8082d74e17fd9454aed9939a386"
   },
   "source": [
    "### Select some features (threshold is not optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a8a6ce954124e2a42dddc19c5f55174f86c8984",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_features = report.loc[report['rmse'] <= 0.7955].index\n",
    "rmses = report.loc[report['rmse'] <= 0.7955, 'rmse'].values\n",
    "good_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75dfb7f6467ba6cddc0648d4452fa4968c63c484",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/santander-value-prediction-challenge/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9144fdbff21261ea77f7a900f15ef079474f4b16",
    "collapsed": true
   },
   "source": [
    "### Add leak to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ed1665c3928cd9063296de5791a7f9b869a7619",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tst_leak = pd.read_csv('../input/breaking-lb-fresh-start-with-lag-selection/test_leak.csv')\n",
    "test['leak'] = tst_leak['compiled_leak']\n",
    "test['log_leak'] = np.log1p(tst_leak['compiled_leak'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d681176d6c0dd3b5fdcdd6ea610fd229368ea57f"
   },
   "source": [
    "### Train lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8d31ec188185853b05a562a97ffa6982b52e1ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Use all features for stats\n",
    "features = [f for f in data if f not in ['ID', 'leak', 'log_leak', 'target']]\n",
    "data.replace(0, np.nan, inplace=True)\n",
    "data['log_of_mean'] = np.log1p(data[features].replace(0, np.nan).mean(axis=1))\n",
    "data['mean_of_log'] = np.log1p(data[features]).replace(0, np.nan).mean(axis=1)\n",
    "data['log_of_median'] = np.log1p(data[features].replace(0, np.nan).median(axis=1))\n",
    "data['nb_nans'] = data[features].isnull().sum(axis=1)\n",
    "data['the_sum'] = np.log1p(data[features].sum(axis=1))\n",
    "data['the_std'] = data[features].std(axis=1)\n",
    "data['the_kur'] = data[features].kurtosis(axis=1)\n",
    "\n",
    "test.replace(0, np.nan, inplace=True)\n",
    "test['log_of_mean'] = np.log1p(test[features].replace(0, np.nan).mean(axis=1))\n",
    "test['mean_of_log'] = np.log1p(test[features]).replace(0, np.nan).mean(axis=1)\n",
    "test['log_of_median'] = np.log1p(test[features].replace(0, np.nan).median(axis=1))\n",
    "test['nb_nans'] = test[features].isnull().sum(axis=1)\n",
    "test['the_sum'] = np.log1p(test[features].sum(axis=1))\n",
    "test['the_std'] = test[features].std(axis=1)\n",
    "test['the_kur'] = test[features].kurtosis(axis=1)\n",
    "\n",
    "# Only use good features, log leak and stats for training\n",
    "features = good_features.tolist()\n",
    "features = features + ['log_leak', 'log_of_mean', 'mean_of_log', 'log_of_median', 'nb_nans', 'the_sum', 'the_std', 'the_kur']\n",
    "dtrain = lgb.Dataset(data=data[features], \n",
    "                     label=target, free_raw_data=False)\n",
    "test['target'] = 0\n",
    "\n",
    "dtrain.construct()\n",
    "oof_preds = np.zeros(data.shape[0])\n",
    "\n",
    "for trn_idx, val_idx in folds.split(data):\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 58,\n",
    "        'subsample': 0.6143,\n",
    "        'colsample_bytree': 0.6453,\n",
    "        'min_split_gain': np.power(10, -2.5988),\n",
    "        'reg_alpha': np.power(10, -2.2887),\n",
    "        'reg_lambda': np.power(10, 1.7570),\n",
    "        'min_child_weight': np.power(10, -0.1477),\n",
    "        'verbose': -1,\n",
    "        'seed': 3,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=dtrain.subset(trn_idx),\n",
    "        valid_sets=dtrain.subset(val_idx),\n",
    "        num_boost_round=10000, \n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=0\n",
    "    )\n",
    "\n",
    "    oof_preds[val_idx] = clf.predict(dtrain.data.iloc[val_idx])\n",
    "    test['target'] += clf.predict(test[features]) / folds.n_splits\n",
    "    print(mean_squared_error(target.iloc[val_idx], \n",
    "                             oof_preds[val_idx]) ** .5)\n",
    "\n",
    "data['predictions'] = oof_preds\n",
    "data.loc[data['leak'].notnull(), 'predictions'] = np.log1p(data.loc[data['leak'].notnull(), 'leak'])\n",
    "print('OOF SCORE : %9.6f' \n",
    "      % (mean_squared_error(target, oof_preds) ** .5))\n",
    "print('OOF SCORE with LEAK : %9.6f' \n",
    "      % (mean_squared_error(target, data['predictions']) ** .5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "949a9ce471a9041d842f94a3a2ad139587b5edd1"
   },
   "source": [
    "### Save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "513e25d309100480da7dcacf2049598b69d7fbe6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['target'] = np.expm1(test['target'])\n",
    "test.loc[test['leak'].notnull(), 'target'] = test.loc[test['leak'].notnull(), 'leak']\n",
    "test[['ID', 'target']].to_csv('leaky_submission.csv', index=False, float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
