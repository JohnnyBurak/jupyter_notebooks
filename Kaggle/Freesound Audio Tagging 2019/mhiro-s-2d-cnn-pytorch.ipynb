{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 520\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dataset_dir = Path('../input/freesound-audio-tagging-2019')\n",
    "preprocessed_dir = Path('../input/fat2019_prep_mels1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'train_curated': dataset_dir / 'train_curated',\n",
    "    'train_noisy': dataset_dir / 'train_noisy',\n",
    "    'test': dataset_dir / 'test',\n",
    "}\n",
    "\n",
    "mels = {\n",
    "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
    "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
    "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>singled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels singled\n",
       "0  0006ae4e.wav             Bark     NaN\n",
       "1  0019ef41.wav         Raindrop     NaN\n",
       "2  001ec0ad.wav  Finger_snapping     NaN\n",
       "3  0026c7cb.wav              Run     NaN\n",
       "4  0026f116.wav  Finger_snapping     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_curated = pd.read_csv(csvs['train_curated'])\n",
    "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...                          0\n",
       "1  0012633b.wav        ...                          0\n",
       "2  001ed5f1.wav        ...                          0\n",
       "3  00294be0.wav        ...                          0\n",
       "4  003fde7a.wav        ...                          0\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(csvs['sample_submission'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accelerating_and_revving_and_vroom',\n",
       " 'Accordion',\n",
       " 'Acoustic_guitar',\n",
       " 'Applause',\n",
       " 'Bark',\n",
       " 'Bass_drum',\n",
       " 'Bass_guitar',\n",
       " 'Bathtub_(filling_or_washing)',\n",
       " 'Bicycle_bell',\n",
       " 'Burping_and_eructation',\n",
       " 'Bus',\n",
       " 'Buzz',\n",
       " 'Car_passing_by',\n",
       " 'Cheering',\n",
       " 'Chewing_and_mastication',\n",
       " 'Child_speech_and_kid_speaking',\n",
       " 'Chink_and_clink',\n",
       " 'Chirp_and_tweet',\n",
       " 'Church_bell',\n",
       " 'Clapping',\n",
       " 'Computer_keyboard',\n",
       " 'Crackle',\n",
       " 'Cricket',\n",
       " 'Crowd',\n",
       " 'Cupboard_open_or_close',\n",
       " 'Cutlery_and_silverware',\n",
       " 'Dishes_and_pots_and_pans',\n",
       " 'Drawer_open_or_close',\n",
       " 'Drip',\n",
       " 'Electric_guitar',\n",
       " 'Fart',\n",
       " 'Female_singing',\n",
       " 'Female_speech_and_woman_speaking',\n",
       " 'Fill_(with_liquid)',\n",
       " 'Finger_snapping',\n",
       " 'Frying_(food)',\n",
       " 'Gasp',\n",
       " 'Glockenspiel',\n",
       " 'Gong',\n",
       " 'Gurgling',\n",
       " 'Harmonica',\n",
       " 'Hi-hat',\n",
       " 'Hiss',\n",
       " 'Keys_jangling',\n",
       " 'Knock',\n",
       " 'Male_singing',\n",
       " 'Male_speech_and_man_speaking',\n",
       " 'Marimba_and_xylophone',\n",
       " 'Mechanical_fan',\n",
       " 'Meow',\n",
       " 'Microwave_oven',\n",
       " 'Motorcycle',\n",
       " 'Printer',\n",
       " 'Purr',\n",
       " 'Race_car_and_auto_racing',\n",
       " 'Raindrop',\n",
       " 'Run',\n",
       " 'Scissors',\n",
       " 'Screaming',\n",
       " 'Shatter',\n",
       " 'Sigh',\n",
       " 'Sink_(filling_or_washing)',\n",
       " 'Skateboard',\n",
       " 'Slam',\n",
       " 'Sneeze',\n",
       " 'Squeak',\n",
       " 'Stream',\n",
       " 'Strum',\n",
       " 'Tap',\n",
       " 'Tick-tock',\n",
       " 'Toilet_flush',\n",
       " 'Traffic_noise_and_roadway_noise',\n",
       " 'Trickle_and_dribble',\n",
       " 'Walk_and_footsteps',\n",
       " 'Water_tap_and_faucet',\n",
       " 'Waves_and_surf',\n",
       " 'Whispering',\n",
       " 'Writing',\n",
       " 'Yell',\n",
       " 'Zipper_(clothing)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = test_df.columns[1:].tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(labels)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
    "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
    "    for label in row:\n",
    "        idx = labels.index(label)\n",
    "        y_train[i, idx] = 1\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 1120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
    "    x_train = pickle.load(curated)\n",
    "    x_train.extend(pickle.load(noisy))\n",
    "\n",
    "with open(mels['test'], 'rb') as test:\n",
    "    x_test = pickle.load(test)\n",
    "    \n",
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, mels, labels, transforms):\n",
    "        super().__init__()\n",
    "        self.mels = mels\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # crop 1sec\n",
    "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        label = torch.from_numpy(label).float()\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTestDataset(Dataset):\n",
    "    def __init__(self, fnames, mels, transforms, tta=5):\n",
    "        super().__init__()\n",
    "        self.fnames = fnames\n",
    "        self.mels = mels\n",
    "        self.transforms = transforms\n",
    "        self.tta = tta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames) * self.tta\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        new_idx = idx % len(self.fnames)\n",
    "        \n",
    "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "\n",
    "        fname = self.fnames[new_idx]\n",
    "        \n",
    "        return image, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print('x')\n",
    "#         print(x.size())\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "#         print('step1')\n",
    "#         print(out.size())\n",
    "        out = self.conv2(out)\n",
    "#         print('step2')\n",
    "#         print(out.size())\n",
    "#         if self.downsample is not None:\n",
    "#             residual = self.downsample(x)\n",
    "#         print('step3')\n",
    "#         print(out.size())\n",
    "#         zeros = torch.zeros_like(out)\n",
    "# #         residual = torch.cat((zeros, residual), 0)\n",
    "#         residual[:,:3, :,:] =zeros \n",
    "#         out= torch.add(out,residual)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=3, out_channels=64),\n",
    "            ConvBlock(in_channels=64, out_channels=128),\n",
    "            ConvBlock(in_channels=128, out_channels=256),\n",
    "            ConvBlock(in_channels=256, out_channels=512)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.2)\n",
       "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout(p=0.1)\n",
       "    (5): Linear(in_features=128, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, train_transforms):\n",
    "    num_epochs = 97\n",
    "    batch_size = 64\n",
    "    test_batch_size = 256\n",
    "    lr = 1e-3\n",
    "    eta_min = 1e-5\n",
    "    t_max = 10\n",
    "    num_classes = y_train.shape[1]\n",
    "\n",
    "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
    "    \n",
    "    train_dataset = FATTrainDataset(x_train, y_train, train_transforms)\n",
    "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes).cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "\n",
    "    best_epoch = -1\n",
    "    best_lwlrap = 0.\n",
    "    mb = master_bar(range(num_epochs))\n",
    "#     print('on')\n",
    "    for epoch in mb:\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "#         print('ok2')\n",
    "#         for x_batch, y_batch in progress_bar(train_loader, parent=mb):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            preds = model(x_batch.cuda())\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        valid_preds = np.zeros((len(x_val), num_classes))\n",
    "        avg_val_loss = 0.\n",
    "#         print('ok3 \\n')\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            preds = model(x_batch.cuda()).detach()\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            preds = torch.sigmoid(preds)\n",
    "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
    "\n",
    "            avg_val_loss += loss.item() / len(valid_loader)\n",
    "#             print('okin')\n",
    "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
    "        lwlrap = (score * weight).sum()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
    "    \n",
    "        if lwlrap > best_lwlrap:\n",
    "            best_epoch = epoch + 1\n",
    "            best_lwlrap = lwlrap\n",
    "            torch.save(model.state_dict(), 'weight_best.pt')\n",
    "#     print('OK4 \\n') \n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_lwlrap': best_lwlrap,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1 - avg_train_loss: 0.4249  avg_val_loss: 0.1112  val_lwlrap: 0.065440  time: 37s<p>Epoch 2 - avg_train_loss: 0.0813  avg_val_loss: 0.0696  val_lwlrap: 0.122515  time: 37s<p>Epoch 3 - avg_train_loss: 0.0699  avg_val_loss: 0.0715  val_lwlrap: 0.081691  time: 37s<p>Epoch 4 - avg_train_loss: 0.0671  avg_val_loss: 0.1393  val_lwlrap: 0.068480  time: 37s<p>Epoch 5 - avg_train_loss: 0.0642  avg_val_loss: 0.0734  val_lwlrap: 0.087525  time: 37s<p>Epoch 6 - avg_train_loss: 0.0622  avg_val_loss: 0.0726  val_lwlrap: 0.113774  time: 37s<p>Epoch 7 - avg_train_loss: 0.0606  avg_val_loss: 0.0786  val_lwlrap: 0.104613  time: 37s<p>Epoch 8 - avg_train_loss: 0.0593  avg_val_loss: 0.0698  val_lwlrap: 0.139329  time: 37s<p>Epoch 9 - avg_train_loss: 0.0579  avg_val_loss: 0.0715  val_lwlrap: 0.147786  time: 37s<p>Epoch 10 - avg_train_loss: 0.0569  avg_val_loss: 0.0564  val_lwlrap: 0.340838  time: 37s<p>Epoch 11 - avg_train_loss: 0.0562  avg_val_loss: 0.0541  val_lwlrap: 0.401968  time: 37s<p>Epoch 12 - avg_train_loss: 0.0560  avg_val_loss: 0.0538  val_lwlrap: 0.399589  time: 37s<p>Epoch 13 - avg_train_loss: 0.0559  avg_val_loss: 0.0546  val_lwlrap: 0.378501  time: 37s<p>Epoch 14 - avg_train_loss: 0.0559  avg_val_loss: 0.0666  val_lwlrap: 0.196405  time: 37s<p>Epoch 15 - avg_train_loss: 0.0556  avg_val_loss: 0.0895  val_lwlrap: 0.115212  time: 37s<p>Epoch 16 - avg_train_loss: 0.0554  avg_val_loss: 0.0775  val_lwlrap: 0.148131  time: 37s<p>Epoch 17 - avg_train_loss: 0.0546  avg_val_loss: 0.0862  val_lwlrap: 0.099304  time: 37s<p>Epoch 18 - avg_train_loss: 0.0535  avg_val_loss: 0.0840  val_lwlrap: 0.087358  time: 37s<p>Epoch 19 - avg_train_loss: 0.0526  avg_val_loss: 0.0926  val_lwlrap: 0.094523  time: 37s<p>Epoch 20 - avg_train_loss: 0.0511  avg_val_loss: 0.1071  val_lwlrap: 0.070610  time: 37s<p>Epoch 21 - avg_train_loss: 0.0499  avg_val_loss: 0.0900  val_lwlrap: 0.078600  time: 37s<p>Epoch 22 - avg_train_loss: 0.0493  avg_val_loss: 0.0995  val_lwlrap: 0.087001  time: 37s<p>Epoch 23 - avg_train_loss: 0.0478  avg_val_loss: 0.0837  val_lwlrap: 0.129380  time: 37s<p>Epoch 24 - avg_train_loss: 0.0464  avg_val_loss: 0.1035  val_lwlrap: 0.073361  time: 37s<p>Epoch 25 - avg_train_loss: 0.0447  avg_val_loss: 0.1141  val_lwlrap: 0.073035  time: 37s<p>Epoch 26 - avg_train_loss: 0.0433  avg_val_loss: 0.1663  val_lwlrap: 0.089082  time: 37s<p>Epoch 27 - avg_train_loss: 0.0421  avg_val_loss: 0.0762  val_lwlrap: 0.228609  time: 37s<p>Epoch 28 - avg_train_loss: 0.0409  avg_val_loss: 0.2060  val_lwlrap: 0.086936  time: 37s<p>Epoch 29 - avg_train_loss: 0.0397  avg_val_loss: 0.0635  val_lwlrap: 0.358525  time: 37s<p>Epoch 30 - avg_train_loss: 0.0388  avg_val_loss: 0.0507  val_lwlrap: 0.454086  time: 37s<p>Epoch 31 - avg_train_loss: 0.0384  avg_val_loss: 0.0336  val_lwlrap: 0.654966  time: 37s<p>Epoch 32 - avg_train_loss: 0.0382  avg_val_loss: 0.0339  val_lwlrap: 0.665874  time: 37s<p>Epoch 33 - avg_train_loss: 0.0379  avg_val_loss: 0.0362  val_lwlrap: 0.630853  time: 37s<p>Epoch 34 - avg_train_loss: 0.0382  avg_val_loss: 0.0516  val_lwlrap: 0.453048  time: 37s<p>Epoch 35 - avg_train_loss: 0.0386  avg_val_loss: 0.0930  val_lwlrap: 0.237194  time: 37s<p>Epoch 36 - avg_train_loss: 0.0388  avg_val_loss: 0.0722  val_lwlrap: 0.246209  time: 37s<p>Epoch 37 - avg_train_loss: 0.0392  avg_val_loss: 0.1915  val_lwlrap: 0.100340  time: 37s<p>Epoch 38 - avg_train_loss: 0.0395  avg_val_loss: 0.5158  val_lwlrap: 0.106885  time: 37s<p>Epoch 39 - avg_train_loss: 0.0403  avg_val_loss: 0.1094  val_lwlrap: 0.104187  time: 37s<p>Epoch 40 - avg_train_loss: 0.0400  avg_val_loss: 0.5740  val_lwlrap: 0.083612  time: 37s<p>Epoch 41 - avg_train_loss: 0.0399  avg_val_loss: 0.1425  val_lwlrap: 0.116206  time: 37s<p>Epoch 42 - avg_train_loss: 0.0389  avg_val_loss: 0.5324  val_lwlrap: 0.082558  time: 37s<p>Epoch 43 - avg_train_loss: 0.0382  avg_val_loss: 0.1265  val_lwlrap: 0.068998  time: 37s<p>Epoch 44 - avg_train_loss: 0.0369  avg_val_loss: 0.4956  val_lwlrap: 0.074418  time: 37s<p>Epoch 45 - avg_train_loss: 0.0361  avg_val_loss: 0.7596  val_lwlrap: 0.102056  time: 37s<p>Epoch 46 - avg_train_loss: 0.0347  avg_val_loss: 0.1188  val_lwlrap: 0.106052  time: 37s<p>Epoch 47 - avg_train_loss: 0.0336  avg_val_loss: 0.1911  val_lwlrap: 0.167814  time: 37s<p>Epoch 48 - avg_train_loss: 0.0324  avg_val_loss: 0.1144  val_lwlrap: 0.164130  time: 37s<p>Epoch 49 - avg_train_loss: 0.0312  avg_val_loss: 0.0821  val_lwlrap: 0.332977  time: 37s<p>Epoch 50 - avg_train_loss: 0.0302  avg_val_loss: 0.0348  val_lwlrap: 0.633877  time: 37s<p>Epoch 51 - avg_train_loss: 0.0297  avg_val_loss: 0.0270  val_lwlrap: 0.745893  time: 37s<p>Epoch 52 - avg_train_loss: 0.0293  avg_val_loss: 0.0240  val_lwlrap: 0.783567  time: 37s<p>Epoch 53 - avg_train_loss: 0.0295  avg_val_loss: 0.0249  val_lwlrap: 0.768742  time: 37s<p>Epoch 54 - avg_train_loss: 0.0296  avg_val_loss: 0.0664  val_lwlrap: 0.397684  time: 37s<p>Epoch 55 - avg_train_loss: 0.0304  avg_val_loss: 0.0997  val_lwlrap: 0.172496  time: 37s<p>Epoch 56 - avg_train_loss: 0.0305  avg_val_loss: 0.1645  val_lwlrap: 0.149212  time: 37s<p>Epoch 57 - avg_train_loss: 0.0310  avg_val_loss: 0.1437  val_lwlrap: 0.122754  time: 37s<p>Epoch 58 - avg_train_loss: 0.0316  avg_val_loss: 0.2255  val_lwlrap: 0.104930  time: 37s<p>Epoch 59 - avg_train_loss: 0.0321  avg_val_loss: 0.2773  val_lwlrap: 0.088920  time: 37s<p>Epoch 60 - avg_train_loss: 0.0327  avg_val_loss: 0.1142  val_lwlrap: 0.069300  time: 37s<p>Epoch 61 - avg_train_loss: 0.0327  avg_val_loss: 0.4338  val_lwlrap: 0.078000  time: 37s<p>Epoch 62 - avg_train_loss: 0.0316  avg_val_loss: 0.1215  val_lwlrap: 0.093702  time: 37s<p>Epoch 63 - avg_train_loss: 0.0312  avg_val_loss: 0.1597  val_lwlrap: 0.063654  time: 37s<p>Epoch 64 - avg_train_loss: 0.0303  avg_val_loss: 0.2487  val_lwlrap: 0.098910  time: 37s<p>Epoch 65 - avg_train_loss: 0.0294  avg_val_loss: 0.1340  val_lwlrap: 0.102129  time: 37s<p>Epoch 66 - avg_train_loss: 0.0283  avg_val_loss: 0.1133  val_lwlrap: 0.199512  time: 37s<p>Epoch 67 - avg_train_loss: 0.0267  avg_val_loss: 0.1473  val_lwlrap: 0.148753  time: 37s<p>Epoch 68 - avg_train_loss: 0.0256  avg_val_loss: 0.1026  val_lwlrap: 0.243339  time: 37s<p>Epoch 69 - avg_train_loss: 0.0248  avg_val_loss: 0.1339  val_lwlrap: 0.345458  time: 37s<p>Epoch 70 - avg_train_loss: 0.0237  avg_val_loss: 0.0501  val_lwlrap: 0.591236  time: 37s<p>Epoch 71 - avg_train_loss: 0.0232  avg_val_loss: 0.0188  val_lwlrap: 0.844077  time: 37s<p>Epoch 72 - avg_train_loss: 0.0228  avg_val_loss: 0.0174  val_lwlrap: 0.853957  time: 37s<p>Epoch 73 - avg_train_loss: 0.0228  avg_val_loss: 0.0187  val_lwlrap: 0.853224  time: 37s<p>Epoch 74 - avg_train_loss: 0.0229  avg_val_loss: 0.0391  val_lwlrap: 0.625160  time: 37s<p>Epoch 75 - avg_train_loss: 0.0233  avg_val_loss: 0.0659  val_lwlrap: 0.467144  time: 37s<p>Epoch 76 - avg_train_loss: 0.0239  avg_val_loss: 0.0964  val_lwlrap: 0.285985  time: 37s<p>Epoch 77 - avg_train_loss: 0.0246  avg_val_loss: 0.1021  val_lwlrap: 0.163085  time: 37s<p>Epoch 78 - avg_train_loss: 0.0255  avg_val_loss: 0.1495  val_lwlrap: 0.073411  time: 37s<p>Epoch 79 - avg_train_loss: 0.0264  avg_val_loss: 0.1065  val_lwlrap: 0.177538  time: 37s<p>Epoch 80 - avg_train_loss: 0.0266  avg_val_loss: 0.1430  val_lwlrap: 0.160400  time: 37s<p>Epoch 81 - avg_train_loss: 0.0265  avg_val_loss: 0.1401  val_lwlrap: 0.063232  time: 37s<p>Epoch 82 - avg_train_loss: 0.0265  avg_val_loss: 0.1992  val_lwlrap: 0.069982  time: 37s<p>Epoch 83 - avg_train_loss: 0.0259  avg_val_loss: 0.2224  val_lwlrap: 0.091743  time: 37s<p>Epoch 84 - avg_train_loss: 0.0254  avg_val_loss: 0.2907  val_lwlrap: 0.073611  time: 37s<p>Epoch 85 - avg_train_loss: 0.0241  avg_val_loss: 0.1308  val_lwlrap: 0.092204  time: 37s<p>Epoch 86 - avg_train_loss: 0.0226  avg_val_loss: 0.1667  val_lwlrap: 0.122710  time: 37s<p>Epoch 87 - avg_train_loss: 0.0210  avg_val_loss: 0.0767  val_lwlrap: 0.266601  time: 37s<p>Epoch 88 - avg_train_loss: 0.0197  avg_val_loss: 0.0716  val_lwlrap: 0.312656  time: 37s<p>Epoch 89 - avg_train_loss: 0.0188  avg_val_loss: 0.0342  val_lwlrap: 0.687728  time: 37s<p>Epoch 90 - avg_train_loss: 0.0180  avg_val_loss: 0.0188  val_lwlrap: 0.836532  time: 37s<p>Epoch 91 - avg_train_loss: 0.0179  avg_val_loss: 0.0140  val_lwlrap: 0.896204  time: 37s<p>Epoch 92 - avg_train_loss: 0.0175  avg_val_loss: 0.0116  val_lwlrap: 0.917113  time: 37s<p>Epoch 93 - avg_train_loss: 0.0176  avg_val_loss: 0.0115  val_lwlrap: 0.915478  time: 37s<p>Epoch 94 - avg_train_loss: 0.0176  avg_val_loss: 0.0354  val_lwlrap: 0.681990  time: 37s<p>Epoch 95 - avg_train_loss: 0.0177  avg_val_loss: 0.0660  val_lwlrap: 0.454991  time: 37s<p>Epoch 96 - avg_train_loss: 0.0184  avg_val_loss: 0.0792  val_lwlrap: 0.360664  time: 37s<p>Epoch 97 - avg_train_loss: 0.0189  avg_val_loss: 0.1152  val_lwlrap: 0.208375  time: 37s"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = train_model(x_train, y_train, transforms_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 92, 'best_lwlrap': 0.9171130825580078}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
    "    batch_size = 256\n",
    "\n",
    "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load('weight_best.pt'))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs, all_fnames = [], []\n",
    "\n",
    "    pb = progress_bar(test_loader)\n",
    "    for images, fnames in pb:\n",
    "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
    "        all_outputs.append(preds.cpu().numpy())\n",
    "        all_fnames.extend(fnames)\n",
    "\n",
    "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                              index=all_fnames,\n",
    "                              columns=map(str, range(num_classes)))\n",
    "    test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='154' class='' max='154', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [154/154 00:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.411247e-08</td>\n",
       "      <td>1.999669e-05</td>\n",
       "      <td>6.790933e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.229608e-07</td>\n",
       "      <td>3.910075e-06</td>\n",
       "      <td>8.376479e-05</td>\n",
       "      <td>1.330323e-04</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>7.595743e-07</td>\n",
       "      <td>4.267113e-03</td>\n",
       "      <td>7.370222e-08</td>\n",
       "      <td>6.519254e-08</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>7.443792e-07</td>\n",
       "      <td>1.751277e-04</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>4.875045e-06</td>\n",
       "      <td>9.099171e-07</td>\n",
       "      <td>7.676282e-06</td>\n",
       "      <td>6.158588e-05</td>\n",
       "      <td>0.086916</td>\n",
       "      <td>5.068293e-07</td>\n",
       "      <td>1.366767e-07</td>\n",
       "      <td>1.362484e-04</td>\n",
       "      <td>9.466098e-06</td>\n",
       "      <td>3.169884e-06</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>5.754897e-08</td>\n",
       "      <td>1.831032e-04</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5.100444e-04</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.156007e-02</td>\n",
       "      <td>2.005289e-03</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>2.209619e-05</td>\n",
       "      <td>7.304593e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.362765e-05</td>\n",
       "      <td>1.498171e-04</td>\n",
       "      <td>0.049426</td>\n",
       "      <td>1.550940e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.082987e-05</td>\n",
       "      <td>7.067253e-06</td>\n",
       "      <td>4.363829e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.266338e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.585198e-06</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.388885e-06</td>\n",
       "      <td>2.355263e-04</td>\n",
       "      <td>9.519675e-07</td>\n",
       "      <td>5.060496e-03</td>\n",
       "      <td>1.942267e-07</td>\n",
       "      <td>3.041226e-06</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>6.174387e-07</td>\n",
       "      <td>2.167766e-08</td>\n",
       "      <td>3.243279e-04</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>2.750217e-06</td>\n",
       "      <td>8.707962e-08</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>1.807108e-05</td>\n",
       "      <td>5.610993e-08</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>2.701127e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>7.907174e-08</td>\n",
       "      <td>1.550362e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0.090256</td>\n",
       "      <td>1.153310e-04</td>\n",
       "      <td>3.470762e-04</td>\n",
       "      <td>3.808106e-03</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>9.416563e-04</td>\n",
       "      <td>2.035910e-02</td>\n",
       "      <td>1.804065e-03</td>\n",
       "      <td>1.582598e-04</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>3.356669e-03</td>\n",
       "      <td>2.450577e-02</td>\n",
       "      <td>2.241689e-03</td>\n",
       "      <td>2.462259e-03</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>4.929584e-04</td>\n",
       "      <td>4.750574e-04</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>3.475114e-03</td>\n",
       "      <td>1.358366e-03</td>\n",
       "      <td>6.637811e-04</td>\n",
       "      <td>5.825125e-03</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>5.472264e-03</td>\n",
       "      <td>6.615304e-04</td>\n",
       "      <td>2.143585e-04</td>\n",
       "      <td>2.555204e-04</td>\n",
       "      <td>5.308507e-03</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>3.027707e-02</td>\n",
       "      <td>6.735456e-03</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>4.996676e-03</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>8.507496e-04</td>\n",
       "      <td>7.856043e-03</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>5.207618e-04</td>\n",
       "      <td>1.737616e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.021759e-03</td>\n",
       "      <td>8.124911e-03</td>\n",
       "      <td>0.052112</td>\n",
       "      <td>1.525161e-03</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>7.209376e-03</td>\n",
       "      <td>1.700857e-02</td>\n",
       "      <td>1.415321e-04</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>1.067095e-03</td>\n",
       "      <td>0.382215</td>\n",
       "      <td>2.774072e-04</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>1.128246e-02</td>\n",
       "      <td>1.562352e-04</td>\n",
       "      <td>2.525857e-03</td>\n",
       "      <td>1.159898e-03</td>\n",
       "      <td>6.251596e-04</td>\n",
       "      <td>3.909810e-02</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>1.740076e-03</td>\n",
       "      <td>2.190851e-03</td>\n",
       "      <td>3.860662e-03</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>1.116224e-03</td>\n",
       "      <td>5.201040e-04</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>3.951279e-03</td>\n",
       "      <td>2.370056e-02</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>9.207258e-03</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>5.840315e-03</td>\n",
       "      <td>1.281001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>5.849048e-04</td>\n",
       "      <td>2.412807e-05</td>\n",
       "      <td>1.977912e-03</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>4.774811e-03</td>\n",
       "      <td>4.017358e-04</td>\n",
       "      <td>1.098494e-03</td>\n",
       "      <td>9.173794e-03</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.141454e-03</td>\n",
       "      <td>3.157439e-04</td>\n",
       "      <td>1.583267e-04</td>\n",
       "      <td>2.448163e-03</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.238618e-04</td>\n",
       "      <td>1.752530e-03</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1.016259e-03</td>\n",
       "      <td>3.829108e-03</td>\n",
       "      <td>9.740416e-03</td>\n",
       "      <td>2.823622e-03</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.686735e-04</td>\n",
       "      <td>1.618003e-02</td>\n",
       "      <td>3.717175e-05</td>\n",
       "      <td>5.162804e-04</td>\n",
       "      <td>2.113958e-02</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>2.145088e-04</td>\n",
       "      <td>1.825881e-05</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>3.506437e-04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>1.417188e-02</td>\n",
       "      <td>1.250443e-04</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.075794e-04</td>\n",
       "      <td>7.427159e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.892998e-04</td>\n",
       "      <td>1.777953e-04</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>1.606442e-04</td>\n",
       "      <td>0.086633</td>\n",
       "      <td>1.615727e-04</td>\n",
       "      <td>2.075065e-04</td>\n",
       "      <td>2.535200e-03</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>8.475382e-03</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>9.331024e-05</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>1.136791e-04</td>\n",
       "      <td>4.291416e-03</td>\n",
       "      <td>6.739685e-01</td>\n",
       "      <td>6.488136e-04</td>\n",
       "      <td>7.823118e-04</td>\n",
       "      <td>1.016012e-03</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>2.269397e-03</td>\n",
       "      <td>5.421690e-02</td>\n",
       "      <td>2.075967e-04</td>\n",
       "      <td>0.036726</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.419174e-05</td>\n",
       "      <td>3.436522e-02</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>6.565514e-05</td>\n",
       "      <td>9.034123e-04</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>1.368931e-04</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>3.212159e-05</td>\n",
       "      <td>3.077117e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>9.246017e-14</td>\n",
       "      <td>1.635689e-08</td>\n",
       "      <td>7.355793e-11</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1.484573e-09</td>\n",
       "      <td>2.394098e-07</td>\n",
       "      <td>6.364571e-08</td>\n",
       "      <td>4.724560e-08</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>5.716663e-08</td>\n",
       "      <td>3.142821e-07</td>\n",
       "      <td>2.300789e-06</td>\n",
       "      <td>1.447569e-09</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>6.353639e-10</td>\n",
       "      <td>1.157820e-07</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.418899e-07</td>\n",
       "      <td>5.515975e-09</td>\n",
       "      <td>1.272987e-08</td>\n",
       "      <td>6.870262e-07</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>5.138251e-10</td>\n",
       "      <td>2.382911e-07</td>\n",
       "      <td>3.524477e-08</td>\n",
       "      <td>1.169012e-11</td>\n",
       "      <td>2.668988e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.464087e-09</td>\n",
       "      <td>2.944015e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.060360e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.457647e-07</td>\n",
       "      <td>4.995941e-07</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.716584e-08</td>\n",
       "      <td>2.903296e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789684e-08</td>\n",
       "      <td>2.506158e-14</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.910016e-07</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>2.380804e-09</td>\n",
       "      <td>8.621420e-07</td>\n",
       "      <td>2.017338e-11</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>9.224353e-11</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6.107708e-09</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>8.008227e-09</td>\n",
       "      <td>2.569404e-08</td>\n",
       "      <td>2.511641e-07</td>\n",
       "      <td>4.652542e-07</td>\n",
       "      <td>4.787375e-08</td>\n",
       "      <td>4.878098e-10</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.882323e-08</td>\n",
       "      <td>1.641252e-08</td>\n",
       "      <td>5.841554e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.215006e-07</td>\n",
       "      <td>7.162236e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.158441e-07</td>\n",
       "      <td>3.763600e-07</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>6.116314e-08</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>6.098651e-09</td>\n",
       "      <td>6.218969e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.692062e-05</td>\n",
       "      <td>8.412741e-07</td>\n",
       "      <td>7.588241e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.765658e-04</td>\n",
       "      <td>1.155834e-04</td>\n",
       "      <td>1.252037e-06</td>\n",
       "      <td>9.035623e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.476436e-04</td>\n",
       "      <td>7.943388e-06</td>\n",
       "      <td>1.694220e-05</td>\n",
       "      <td>7.395888e-06</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>5.633732e-07</td>\n",
       "      <td>9.952240e-04</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.799495e-05</td>\n",
       "      <td>1.184102e-07</td>\n",
       "      <td>2.527470e-05</td>\n",
       "      <td>3.887584e-06</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>9.555858e-07</td>\n",
       "      <td>4.015119e-05</td>\n",
       "      <td>1.494044e-04</td>\n",
       "      <td>6.043123e-04</td>\n",
       "      <td>1.165467e-04</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>2.341089e-05</td>\n",
       "      <td>8.619690e-08</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.918794e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.098630e-05</td>\n",
       "      <td>7.452868e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.731383e-01</td>\n",
       "      <td>1.281449e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.747065e-05</td>\n",
       "      <td>1.094505e-05</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>3.409482e-05</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>4.547246e-05</td>\n",
       "      <td>1.108294e-05</td>\n",
       "      <td>8.984935e-03</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.787910e-03</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.288218e-04</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.625195e-05</td>\n",
       "      <td>3.334010e-05</td>\n",
       "      <td>1.111557e-05</td>\n",
       "      <td>3.177435e-06</td>\n",
       "      <td>6.022875e-05</td>\n",
       "      <td>1.077917e-03</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>2.706770e-07</td>\n",
       "      <td>6.155788e-05</td>\n",
       "      <td>4.317052e-07</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.450494e-07</td>\n",
       "      <td>3.324457e-05</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.267519e-05</td>\n",
       "      <td>4.393014e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.711467e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.193748e-06</td>\n",
       "      <td>3.082688e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...               1.550362e-05\n",
       "1  0012633b.wav        ...               1.281001e-01\n",
       "2  001ed5f1.wav        ...               3.077117e-04\n",
       "3  00294be0.wav        ...               6.218969e-02\n",
       "4  003fde7a.wav        ...               3.082688e-07\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[labels] = test_preds.values\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
