{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'merchants.csv', 'sample_submission.csv', 'test.csv', 'historical_transactions.csv', 'Data_Dictionary.xlsx', 'new_merchant_transactions.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b3143b13f6cc576b2ab4b0ec46a6a648676d9a14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:03:50:25 <ipython-input-3-9f640adaf07c>: 237: read historical_transactions (29112361, 14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1832.41 MB\n",
      "Decreased by 71.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:04:04:42 <ipython-input-3-9f640adaf07c>: 45: historical transactions - done in 920s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 66.13 MB\n",
      "Decreased by 56.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:04:04:46 <ipython-input-3-9f640adaf07c>: 350: read new_merchant_transactions (1963031, 14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 117.94 MB\n",
      "Decreased by 69.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:04:12:36 <ipython-input-3-9f640adaf07c>: 45: new merchants - done in 474s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 47.29 MB\n",
      "Decreased by 59.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:04:12:38 <ipython-input-3-9f640adaf07c>: 146: samples: train (201917, 5), test: (123623, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 8.67 MB\n",
      "Decreased by 73.2%\n",
      "Memory usage after optimization is: 5.07 MB\n",
      "Decreased by 71.7%\n",
      "Memory usage after optimization is: 101.10 MB\n",
      "Decreased by 26.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:04:12:43 <ipython-input-3-9f640adaf07c>: 45: additional features - done in 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 60.24 MB\n",
      "Decreased by 28.5%\n",
      "no 0 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.83655\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.73369\n",
      "[100]\tvalidation_0-rmse:3.67671\n",
      "[150]\tvalidation_0-rmse:3.64569\n",
      "[200]\tvalidation_0-rmse:3.62928\n",
      "[250]\tvalidation_0-rmse:3.62081\n",
      "[300]\tvalidation_0-rmse:3.61569\n",
      "[350]\tvalidation_0-rmse:3.61193\n",
      "[400]\tvalidation_0-rmse:3.60963\n",
      "[450]\tvalidation_0-rmse:3.60776\n",
      "[500]\tvalidation_0-rmse:3.60665\n",
      "[550]\tvalidation_0-rmse:3.6055\n",
      "[600]\tvalidation_0-rmse:3.60507\n",
      "[650]\tvalidation_0-rmse:3.60463\n",
      "[700]\tvalidation_0-rmse:3.60405\n",
      "[750]\tvalidation_0-rmse:3.60399\n",
      "[800]\tvalidation_0-rmse:3.60375\n",
      "[850]\tvalidation_0-rmse:3.60325\n",
      "[900]\tvalidation_0-rmse:3.60314\n",
      "[950]\tvalidation_0-rmse:3.60248\n",
      "[1000]\tvalidation_0-rmse:3.60203\n",
      "[1050]\tvalidation_0-rmse:3.60228\n",
      "[1100]\tvalidation_0-rmse:3.60186\n",
      "[1150]\tvalidation_0-rmse:3.60171\n",
      "[1200]\tvalidation_0-rmse:3.60161\n",
      "[1250]\tvalidation_0-rmse:3.60127\n",
      "[1300]\tvalidation_0-rmse:3.60103\n",
      "[1350]\tvalidation_0-rmse:3.6013\n",
      "[1400]\tvalidation_0-rmse:3.6013\n",
      "[1450]\tvalidation_0-rmse:3.6014\n",
      "[1500]\tvalidation_0-rmse:3.60137\n",
      "[1550]\tvalidation_0-rmse:3.60147\n",
      "[1600]\tvalidation_0-rmse:3.60164\n",
      "[1650]\tvalidation_0-rmse:3.60151\n",
      "[1700]\tvalidation_0-rmse:3.60151\n",
      "[1750]\tvalidation_0-rmse:3.60137\n",
      "[1800]\tvalidation_0-rmse:3.60171\n",
      "Stopping. Best iteration:\n",
      "[1303]\tvalidation_0-rmse:3.60098\n",
      "\n",
      "no 1 of 11 folds\n",
      "[0]\tvalidation_0-rmse:4.02302\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.90679\n",
      "[100]\tvalidation_0-rmse:3.83759\n",
      "[150]\tvalidation_0-rmse:3.79605\n",
      "[200]\tvalidation_0-rmse:3.76995\n",
      "[250]\tvalidation_0-rmse:3.75358\n",
      "[300]\tvalidation_0-rmse:3.74255\n",
      "[350]\tvalidation_0-rmse:3.73522\n",
      "[400]\tvalidation_0-rmse:3.73013\n",
      "[450]\tvalidation_0-rmse:3.72561\n",
      "[500]\tvalidation_0-rmse:3.72239\n",
      "[550]\tvalidation_0-rmse:3.71962\n",
      "[600]\tvalidation_0-rmse:3.71752\n",
      "[650]\tvalidation_0-rmse:3.71532\n",
      "[700]\tvalidation_0-rmse:3.71369\n",
      "[750]\tvalidation_0-rmse:3.71287\n",
      "[800]\tvalidation_0-rmse:3.71172\n",
      "[850]\tvalidation_0-rmse:3.71054\n",
      "[900]\tvalidation_0-rmse:3.70974\n",
      "[950]\tvalidation_0-rmse:3.70901\n",
      "[1000]\tvalidation_0-rmse:3.70849\n",
      "[1050]\tvalidation_0-rmse:3.70724\n",
      "[1100]\tvalidation_0-rmse:3.70678\n",
      "[1150]\tvalidation_0-rmse:3.70642\n",
      "[1200]\tvalidation_0-rmse:3.70581\n",
      "[1250]\tvalidation_0-rmse:3.70502\n",
      "[1300]\tvalidation_0-rmse:3.70462\n",
      "[1350]\tvalidation_0-rmse:3.70416\n",
      "[1400]\tvalidation_0-rmse:3.70376\n",
      "[1450]\tvalidation_0-rmse:3.70335\n",
      "[1500]\tvalidation_0-rmse:3.70327\n",
      "[1550]\tvalidation_0-rmse:3.70309\n",
      "[1600]\tvalidation_0-rmse:3.70294\n",
      "[1650]\tvalidation_0-rmse:3.70286\n",
      "[1700]\tvalidation_0-rmse:3.70253\n",
      "[1750]\tvalidation_0-rmse:3.70228\n",
      "[1800]\tvalidation_0-rmse:3.70212\n",
      "[1850]\tvalidation_0-rmse:3.70206\n",
      "[1900]\tvalidation_0-rmse:3.70219\n",
      "[1950]\tvalidation_0-rmse:3.70194\n",
      "[2000]\tvalidation_0-rmse:3.70209\n",
      "[2050]\tvalidation_0-rmse:3.70225\n",
      "[2100]\tvalidation_0-rmse:3.70222\n",
      "[2150]\tvalidation_0-rmse:3.70225\n",
      "[2200]\tvalidation_0-rmse:3.7022\n",
      "[2250]\tvalidation_0-rmse:3.70227\n",
      "[2300]\tvalidation_0-rmse:3.70221\n",
      "[2350]\tvalidation_0-rmse:3.70237\n",
      "[2400]\tvalidation_0-rmse:3.70214\n",
      "Stopping. Best iteration:\n",
      "[1933]\tvalidation_0-rmse:3.70194\n",
      "\n",
      "no 2 of 11 folds\n",
      "[0]\tvalidation_0-rmse:4.07829\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.95892\n",
      "[100]\tvalidation_0-rmse:3.88714\n",
      "[150]\tvalidation_0-rmse:3.84412\n",
      "[200]\tvalidation_0-rmse:3.8165\n",
      "[250]\tvalidation_0-rmse:3.79714\n",
      "[300]\tvalidation_0-rmse:3.78529\n",
      "[350]\tvalidation_0-rmse:3.77741\n",
      "[400]\tvalidation_0-rmse:3.77083\n",
      "[450]\tvalidation_0-rmse:3.76613\n",
      "[500]\tvalidation_0-rmse:3.76265\n",
      "[550]\tvalidation_0-rmse:3.75977\n",
      "[600]\tvalidation_0-rmse:3.75727\n",
      "[650]\tvalidation_0-rmse:3.75548\n",
      "[700]\tvalidation_0-rmse:3.75363\n",
      "[750]\tvalidation_0-rmse:3.75179\n",
      "[800]\tvalidation_0-rmse:3.75073\n",
      "[850]\tvalidation_0-rmse:3.74955\n",
      "[900]\tvalidation_0-rmse:3.7482\n",
      "[950]\tvalidation_0-rmse:3.74745\n",
      "[1000]\tvalidation_0-rmse:3.74713\n",
      "[1050]\tvalidation_0-rmse:3.74644\n",
      "[1100]\tvalidation_0-rmse:3.74585\n",
      "[1150]\tvalidation_0-rmse:3.74571\n",
      "[1200]\tvalidation_0-rmse:3.74509\n",
      "[1250]\tvalidation_0-rmse:3.7447\n",
      "[1300]\tvalidation_0-rmse:3.744\n",
      "[1350]\tvalidation_0-rmse:3.74377\n",
      "[1400]\tvalidation_0-rmse:3.74394\n",
      "[1450]\tvalidation_0-rmse:3.74345\n",
      "[1500]\tvalidation_0-rmse:3.74358\n",
      "[1550]\tvalidation_0-rmse:3.74353\n",
      "[1600]\tvalidation_0-rmse:3.74367\n",
      "[1650]\tvalidation_0-rmse:3.74367\n",
      "[1700]\tvalidation_0-rmse:3.74326\n",
      "[1750]\tvalidation_0-rmse:3.74335\n",
      "[1800]\tvalidation_0-rmse:3.74328\n",
      "[1850]\tvalidation_0-rmse:3.74327\n",
      "[1900]\tvalidation_0-rmse:3.74331\n",
      "[1950]\tvalidation_0-rmse:3.7432\n",
      "[2000]\tvalidation_0-rmse:3.74336\n",
      "[2050]\tvalidation_0-rmse:3.7435\n",
      "[2100]\tvalidation_0-rmse:3.74357\n",
      "[2150]\tvalidation_0-rmse:3.74349\n",
      "[2200]\tvalidation_0-rmse:3.74347\n",
      "[2250]\tvalidation_0-rmse:3.7436\n",
      "[2300]\tvalidation_0-rmse:3.74355\n",
      "[2350]\tvalidation_0-rmse:3.74371\n",
      "[2400]\tvalidation_0-rmse:3.7442\n",
      "[2450]\tvalidation_0-rmse:3.74452\n",
      "Stopping. Best iteration:\n",
      "[1982]\tvalidation_0-rmse:3.74311\n",
      "\n",
      "no 3 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.90012\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.79328\n",
      "[100]\tvalidation_0-rmse:3.73005\n",
      "[150]\tvalidation_0-rmse:3.69195\n",
      "[200]\tvalidation_0-rmse:3.66907\n",
      "[250]\tvalidation_0-rmse:3.65382\n",
      "[300]\tvalidation_0-rmse:3.64393\n",
      "[350]\tvalidation_0-rmse:3.63682\n",
      "[400]\tvalidation_0-rmse:3.63225\n",
      "[450]\tvalidation_0-rmse:3.62884\n",
      "[500]\tvalidation_0-rmse:3.62617\n",
      "[550]\tvalidation_0-rmse:3.62358\n",
      "[600]\tvalidation_0-rmse:3.62144\n",
      "[650]\tvalidation_0-rmse:3.61998\n",
      "[700]\tvalidation_0-rmse:3.6184\n",
      "[750]\tvalidation_0-rmse:3.61728\n",
      "[800]\tvalidation_0-rmse:3.61624\n",
      "[850]\tvalidation_0-rmse:3.61525\n",
      "[900]\tvalidation_0-rmse:3.61465\n",
      "[950]\tvalidation_0-rmse:3.61398\n",
      "[1000]\tvalidation_0-rmse:3.61311\n",
      "[1050]\tvalidation_0-rmse:3.61262\n",
      "[1100]\tvalidation_0-rmse:3.61204\n",
      "[1150]\tvalidation_0-rmse:3.61178\n",
      "[1200]\tvalidation_0-rmse:3.61138\n",
      "[1250]\tvalidation_0-rmse:3.61092\n",
      "[1300]\tvalidation_0-rmse:3.61094\n",
      "[1350]\tvalidation_0-rmse:3.61068\n",
      "[1400]\tvalidation_0-rmse:3.61059\n",
      "[1450]\tvalidation_0-rmse:3.61037\n",
      "[1500]\tvalidation_0-rmse:3.61017\n",
      "[1550]\tvalidation_0-rmse:3.60998\n",
      "[1600]\tvalidation_0-rmse:3.60976\n",
      "[1650]\tvalidation_0-rmse:3.6096\n",
      "[1700]\tvalidation_0-rmse:3.60943\n",
      "[1750]\tvalidation_0-rmse:3.60935\n",
      "[1800]\tvalidation_0-rmse:3.60941\n",
      "[1850]\tvalidation_0-rmse:3.60949\n",
      "[1900]\tvalidation_0-rmse:3.60934\n",
      "[1950]\tvalidation_0-rmse:3.60933\n",
      "[2000]\tvalidation_0-rmse:3.60905\n",
      "[2050]\tvalidation_0-rmse:3.60896\n",
      "[2100]\tvalidation_0-rmse:3.60895\n",
      "[2150]\tvalidation_0-rmse:3.60903\n",
      "[2200]\tvalidation_0-rmse:3.60887\n",
      "[2250]\tvalidation_0-rmse:3.60891\n",
      "[2300]\tvalidation_0-rmse:3.60925\n",
      "[2350]\tvalidation_0-rmse:3.60872\n",
      "[2400]\tvalidation_0-rmse:3.60859\n",
      "[2450]\tvalidation_0-rmse:3.60855\n",
      "[2500]\tvalidation_0-rmse:3.60867\n",
      "[2550]\tvalidation_0-rmse:3.6088\n",
      "[2600]\tvalidation_0-rmse:3.60886\n",
      "[2650]\tvalidation_0-rmse:3.60889\n",
      "[2700]\tvalidation_0-rmse:3.60882\n",
      "[2750]\tvalidation_0-rmse:3.60902\n",
      "[2800]\tvalidation_0-rmse:3.60924\n",
      "[2850]\tvalidation_0-rmse:3.60925\n",
      "[2900]\tvalidation_0-rmse:3.60925\n",
      "Stopping. Best iteration:\n",
      "[2441]\tvalidation_0-rmse:3.60842\n",
      "\n",
      "no 4 of 11 folds\n",
      "[0]\tvalidation_0-rmse:4.01024\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.89605\n",
      "[100]\tvalidation_0-rmse:3.82727\n",
      "[150]\tvalidation_0-rmse:3.78576\n",
      "[200]\tvalidation_0-rmse:3.76069\n",
      "[250]\tvalidation_0-rmse:3.74319\n",
      "[300]\tvalidation_0-rmse:3.7326\n",
      "[350]\tvalidation_0-rmse:3.72478\n",
      "[400]\tvalidation_0-rmse:3.71848\n",
      "[450]\tvalidation_0-rmse:3.71452\n",
      "[500]\tvalidation_0-rmse:3.71192\n",
      "[550]\tvalidation_0-rmse:3.70955\n",
      "[600]\tvalidation_0-rmse:3.70797\n",
      "[650]\tvalidation_0-rmse:3.70706\n",
      "[700]\tvalidation_0-rmse:3.70579\n",
      "[750]\tvalidation_0-rmse:3.70484\n",
      "[800]\tvalidation_0-rmse:3.70401\n",
      "[850]\tvalidation_0-rmse:3.70317\n",
      "[900]\tvalidation_0-rmse:3.70248\n",
      "[950]\tvalidation_0-rmse:3.70202\n",
      "[1000]\tvalidation_0-rmse:3.70148\n",
      "[1050]\tvalidation_0-rmse:3.70083\n",
      "[1100]\tvalidation_0-rmse:3.70055\n",
      "[1150]\tvalidation_0-rmse:3.70044\n",
      "[1200]\tvalidation_0-rmse:3.70045\n",
      "[1250]\tvalidation_0-rmse:3.70027\n",
      "[1300]\tvalidation_0-rmse:3.69989\n",
      "[1350]\tvalidation_0-rmse:3.69967\n",
      "[1400]\tvalidation_0-rmse:3.69944\n",
      "[1450]\tvalidation_0-rmse:3.69948\n",
      "[1500]\tvalidation_0-rmse:3.69928\n",
      "[1550]\tvalidation_0-rmse:3.69918\n",
      "[1600]\tvalidation_0-rmse:3.69932\n",
      "[1650]\tvalidation_0-rmse:3.69924\n",
      "[1700]\tvalidation_0-rmse:3.69921\n",
      "[1750]\tvalidation_0-rmse:3.69919\n",
      "[1800]\tvalidation_0-rmse:3.69908\n",
      "[1850]\tvalidation_0-rmse:3.69929\n",
      "[1900]\tvalidation_0-rmse:3.69932\n",
      "[1950]\tvalidation_0-rmse:3.69943\n",
      "[2000]\tvalidation_0-rmse:3.69956\n",
      "[2050]\tvalidation_0-rmse:3.69952\n",
      "[2100]\tvalidation_0-rmse:3.69939\n",
      "[2150]\tvalidation_0-rmse:3.69958\n",
      "[2200]\tvalidation_0-rmse:3.69988\n",
      "[2250]\tvalidation_0-rmse:3.69983\n",
      "Stopping. Best iteration:\n",
      "[1797]\tvalidation_0-rmse:3.69904\n",
      "\n",
      "no 5 of 11 folds\n",
      "[0]\tvalidation_0-rmse:4.0551\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.94912\n",
      "[100]\tvalidation_0-rmse:3.88537\n",
      "[150]\tvalidation_0-rmse:3.84829\n",
      "[200]\tvalidation_0-rmse:3.82468\n",
      "[250]\tvalidation_0-rmse:3.81073\n",
      "[300]\tvalidation_0-rmse:3.80024\n",
      "[350]\tvalidation_0-rmse:3.7929\n",
      "[400]\tvalidation_0-rmse:3.78759\n",
      "[450]\tvalidation_0-rmse:3.78429\n",
      "[500]\tvalidation_0-rmse:3.78117\n",
      "[550]\tvalidation_0-rmse:3.77849\n",
      "[600]\tvalidation_0-rmse:3.77629\n",
      "[650]\tvalidation_0-rmse:3.77433\n",
      "[700]\tvalidation_0-rmse:3.77301\n",
      "[750]\tvalidation_0-rmse:3.77196\n",
      "[800]\tvalidation_0-rmse:3.77035\n",
      "[850]\tvalidation_0-rmse:3.76934\n",
      "[900]\tvalidation_0-rmse:3.76872\n",
      "[950]\tvalidation_0-rmse:3.7678\n",
      "[1000]\tvalidation_0-rmse:3.76719\n",
      "[1050]\tvalidation_0-rmse:3.76628\n",
      "[1100]\tvalidation_0-rmse:3.76574\n",
      "[1150]\tvalidation_0-rmse:3.76507\n",
      "[1200]\tvalidation_0-rmse:3.76492\n",
      "[1250]\tvalidation_0-rmse:3.76448\n",
      "[1300]\tvalidation_0-rmse:3.76416\n",
      "[1350]\tvalidation_0-rmse:3.76398\n",
      "[1400]\tvalidation_0-rmse:3.76366\n",
      "[1450]\tvalidation_0-rmse:3.76365\n",
      "[1500]\tvalidation_0-rmse:3.76319\n",
      "[1550]\tvalidation_0-rmse:3.76316\n",
      "[1600]\tvalidation_0-rmse:3.76304\n",
      "[1650]\tvalidation_0-rmse:3.76279\n",
      "[1700]\tvalidation_0-rmse:3.76242\n",
      "[1750]\tvalidation_0-rmse:3.76212\n",
      "[1800]\tvalidation_0-rmse:3.76188\n",
      "[1850]\tvalidation_0-rmse:3.76208\n",
      "[1900]\tvalidation_0-rmse:3.76186\n",
      "[1950]\tvalidation_0-rmse:3.76187\n",
      "[2000]\tvalidation_0-rmse:3.76177\n",
      "[2050]\tvalidation_0-rmse:3.76157\n",
      "[2100]\tvalidation_0-rmse:3.76124\n",
      "[2150]\tvalidation_0-rmse:3.76097\n",
      "[2200]\tvalidation_0-rmse:3.7609\n",
      "[2250]\tvalidation_0-rmse:3.76077\n",
      "[2300]\tvalidation_0-rmse:3.76089\n",
      "[2350]\tvalidation_0-rmse:3.76091\n",
      "[2400]\tvalidation_0-rmse:3.76094\n",
      "[2450]\tvalidation_0-rmse:3.7608\n",
      "[2500]\tvalidation_0-rmse:3.76074\n",
      "[2550]\tvalidation_0-rmse:3.76074\n",
      "[2600]\tvalidation_0-rmse:3.7606\n",
      "[2650]\tvalidation_0-rmse:3.76068\n",
      "[2700]\tvalidation_0-rmse:3.76088\n",
      "[2750]\tvalidation_0-rmse:3.76106\n",
      "[2800]\tvalidation_0-rmse:3.76095\n",
      "[2850]\tvalidation_0-rmse:3.7611\n",
      "[2900]\tvalidation_0-rmse:3.761\n",
      "[2950]\tvalidation_0-rmse:3.76108\n",
      "[3000]\tvalidation_0-rmse:3.76106\n",
      "[3050]\tvalidation_0-rmse:3.76115\n",
      "[3100]\tvalidation_0-rmse:3.76131\n",
      "Stopping. Best iteration:\n",
      "[2619]\tvalidation_0-rmse:3.76049\n",
      "\n",
      "no 6 of 11 folds\n",
      "[0]\tvalidation_0-rmse:4.06962\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.95709\n",
      "[100]\tvalidation_0-rmse:3.88981\n",
      "[150]\tvalidation_0-rmse:3.84872\n",
      "[200]\tvalidation_0-rmse:3.82259\n",
      "[250]\tvalidation_0-rmse:3.80529\n",
      "[300]\tvalidation_0-rmse:3.79286\n",
      "[350]\tvalidation_0-rmse:3.78397\n",
      "[400]\tvalidation_0-rmse:3.77722\n",
      "[450]\tvalidation_0-rmse:3.77229\n",
      "[500]\tvalidation_0-rmse:3.76864\n",
      "[550]\tvalidation_0-rmse:3.76579\n",
      "[600]\tvalidation_0-rmse:3.76369\n",
      "[650]\tvalidation_0-rmse:3.76213\n",
      "[700]\tvalidation_0-rmse:3.76013\n",
      "[750]\tvalidation_0-rmse:3.7587\n",
      "[800]\tvalidation_0-rmse:3.75794\n",
      "[850]\tvalidation_0-rmse:3.75681\n",
      "[900]\tvalidation_0-rmse:3.75622\n",
      "[950]\tvalidation_0-rmse:3.75545\n",
      "[1000]\tvalidation_0-rmse:3.75448\n",
      "[1050]\tvalidation_0-rmse:3.75376\n",
      "[1100]\tvalidation_0-rmse:3.75317\n",
      "[1150]\tvalidation_0-rmse:3.75271\n",
      "[1200]\tvalidation_0-rmse:3.75256\n",
      "[1250]\tvalidation_0-rmse:3.7523\n",
      "[1300]\tvalidation_0-rmse:3.75175\n",
      "[1350]\tvalidation_0-rmse:3.75101\n",
      "[1400]\tvalidation_0-rmse:3.7505\n",
      "[1450]\tvalidation_0-rmse:3.75033\n",
      "[1500]\tvalidation_0-rmse:3.74978\n",
      "[1550]\tvalidation_0-rmse:3.74938\n",
      "[1600]\tvalidation_0-rmse:3.74904\n",
      "[1650]\tvalidation_0-rmse:3.74867\n",
      "[1700]\tvalidation_0-rmse:3.74858\n",
      "[1750]\tvalidation_0-rmse:3.74835\n",
      "[1800]\tvalidation_0-rmse:3.74832\n",
      "[1850]\tvalidation_0-rmse:3.74826\n",
      "[1900]\tvalidation_0-rmse:3.74814\n",
      "[1950]\tvalidation_0-rmse:3.74817\n",
      "[2000]\tvalidation_0-rmse:3.74808\n",
      "[2050]\tvalidation_0-rmse:3.74817\n",
      "[2100]\tvalidation_0-rmse:3.74803\n",
      "[2150]\tvalidation_0-rmse:3.74805\n",
      "[2200]\tvalidation_0-rmse:3.74785\n",
      "[2250]\tvalidation_0-rmse:3.74793\n",
      "[2300]\tvalidation_0-rmse:3.74784\n",
      "[2350]\tvalidation_0-rmse:3.74772\n",
      "[2400]\tvalidation_0-rmse:3.74763\n",
      "[2450]\tvalidation_0-rmse:3.74769\n",
      "[2500]\tvalidation_0-rmse:3.74752\n",
      "[2550]\tvalidation_0-rmse:3.74713\n",
      "[2600]\tvalidation_0-rmse:3.74704\n",
      "[2650]\tvalidation_0-rmse:3.74715\n",
      "[2700]\tvalidation_0-rmse:3.74662\n",
      "[2750]\tvalidation_0-rmse:3.74669\n",
      "[2800]\tvalidation_0-rmse:3.74679\n",
      "[2850]\tvalidation_0-rmse:3.74663\n",
      "[2900]\tvalidation_0-rmse:3.74673\n",
      "[2950]\tvalidation_0-rmse:3.74696\n",
      "[3000]\tvalidation_0-rmse:3.74719\n",
      "[3050]\tvalidation_0-rmse:3.74744\n",
      "[3100]\tvalidation_0-rmse:3.7477\n",
      "[3150]\tvalidation_0-rmse:3.7476\n",
      "[3200]\tvalidation_0-rmse:3.74736\n",
      "[3250]\tvalidation_0-rmse:3.74732\n",
      "[3300]\tvalidation_0-rmse:3.74718\n",
      "[3350]\tvalidation_0-rmse:3.74717\n",
      "Stopping. Best iteration:\n",
      "[2870]\tvalidation_0-rmse:3.74653\n",
      "\n",
      "no 7 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.80353\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.69341\n",
      "[100]\tvalidation_0-rmse:3.63027\n",
      "[150]\tvalidation_0-rmse:3.59453\n",
      "[200]\tvalidation_0-rmse:3.57333\n",
      "[250]\tvalidation_0-rmse:3.5616\n",
      "[300]\tvalidation_0-rmse:3.55411\n",
      "[350]\tvalidation_0-rmse:3.55004\n",
      "[400]\tvalidation_0-rmse:3.54661\n",
      "[450]\tvalidation_0-rmse:3.54443\n",
      "[500]\tvalidation_0-rmse:3.54228\n",
      "[550]\tvalidation_0-rmse:3.5412\n",
      "[600]\tvalidation_0-rmse:3.53994\n",
      "[650]\tvalidation_0-rmse:3.53943\n",
      "[700]\tvalidation_0-rmse:3.53916\n",
      "[750]\tvalidation_0-rmse:3.53832\n",
      "[800]\tvalidation_0-rmse:3.53801\n",
      "[850]\tvalidation_0-rmse:3.53779\n",
      "[900]\tvalidation_0-rmse:3.53795\n",
      "[950]\tvalidation_0-rmse:3.53775\n",
      "[1000]\tvalidation_0-rmse:3.53761\n",
      "[1050]\tvalidation_0-rmse:3.53767\n",
      "[1100]\tvalidation_0-rmse:3.53735\n",
      "[1150]\tvalidation_0-rmse:3.53711\n",
      "[1200]\tvalidation_0-rmse:3.53709\n",
      "[1250]\tvalidation_0-rmse:3.5369\n",
      "[1300]\tvalidation_0-rmse:3.53686\n",
      "[1350]\tvalidation_0-rmse:3.5367\n",
      "[1400]\tvalidation_0-rmse:3.53704\n",
      "[1450]\tvalidation_0-rmse:3.53684\n",
      "[1500]\tvalidation_0-rmse:3.5364\n",
      "[1550]\tvalidation_0-rmse:3.53614\n",
      "[1600]\tvalidation_0-rmse:3.53586\n",
      "[1650]\tvalidation_0-rmse:3.53602\n",
      "[1700]\tvalidation_0-rmse:3.53581\n",
      "[1750]\tvalidation_0-rmse:3.5356\n",
      "[1800]\tvalidation_0-rmse:3.53555\n",
      "[1850]\tvalidation_0-rmse:3.5356\n",
      "[1900]\tvalidation_0-rmse:3.53579\n",
      "[1950]\tvalidation_0-rmse:3.53563\n",
      "[2000]\tvalidation_0-rmse:3.53565\n",
      "[2050]\tvalidation_0-rmse:3.53565\n",
      "[2100]\tvalidation_0-rmse:3.53578\n",
      "[2150]\tvalidation_0-rmse:3.53557\n",
      "[2200]\tvalidation_0-rmse:3.53549\n",
      "[2250]\tvalidation_0-rmse:3.53519\n",
      "[2300]\tvalidation_0-rmse:3.53513\n",
      "[2350]\tvalidation_0-rmse:3.53506\n",
      "[2400]\tvalidation_0-rmse:3.53495\n",
      "[2450]\tvalidation_0-rmse:3.53467\n",
      "[2500]\tvalidation_0-rmse:3.53462\n",
      "[2550]\tvalidation_0-rmse:3.53489\n",
      "[2600]\tvalidation_0-rmse:3.53503\n",
      "[2650]\tvalidation_0-rmse:3.53494\n",
      "[2700]\tvalidation_0-rmse:3.53516\n",
      "[2750]\tvalidation_0-rmse:3.5352\n",
      "[2800]\tvalidation_0-rmse:3.53501\n",
      "[2850]\tvalidation_0-rmse:3.53506\n",
      "[2900]\tvalidation_0-rmse:3.53511\n",
      "[2950]\tvalidation_0-rmse:3.53529\n",
      "Stopping. Best iteration:\n",
      "[2488]\tvalidation_0-rmse:3.53452\n",
      "\n",
      "no 8 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.86563\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.75564\n",
      "[100]\tvalidation_0-rmse:3.69225\n",
      "[150]\tvalidation_0-rmse:3.65564\n",
      "[200]\tvalidation_0-rmse:3.63336\n",
      "[250]\tvalidation_0-rmse:3.62041\n",
      "[300]\tvalidation_0-rmse:3.61211\n",
      "[350]\tvalidation_0-rmse:3.60602\n",
      "[400]\tvalidation_0-rmse:3.60039\n",
      "[450]\tvalidation_0-rmse:3.59664\n",
      "[500]\tvalidation_0-rmse:3.59356\n",
      "[550]\tvalidation_0-rmse:3.5912\n",
      "[600]\tvalidation_0-rmse:3.58906\n",
      "[650]\tvalidation_0-rmse:3.58703\n",
      "[700]\tvalidation_0-rmse:3.58586\n",
      "[750]\tvalidation_0-rmse:3.58414\n",
      "[800]\tvalidation_0-rmse:3.58332\n",
      "[850]\tvalidation_0-rmse:3.58263\n",
      "[900]\tvalidation_0-rmse:3.58162\n",
      "[950]\tvalidation_0-rmse:3.58139\n",
      "[1000]\tvalidation_0-rmse:3.58098\n",
      "[1050]\tvalidation_0-rmse:3.57992\n",
      "[1100]\tvalidation_0-rmse:3.57957\n",
      "[1150]\tvalidation_0-rmse:3.57917\n",
      "[1200]\tvalidation_0-rmse:3.57862\n",
      "[1250]\tvalidation_0-rmse:3.57842\n",
      "[1300]\tvalidation_0-rmse:3.57826\n",
      "[1350]\tvalidation_0-rmse:3.57775\n",
      "[1400]\tvalidation_0-rmse:3.57747\n",
      "[1450]\tvalidation_0-rmse:3.57715\n",
      "[1500]\tvalidation_0-rmse:3.57653\n",
      "[1550]\tvalidation_0-rmse:3.57659\n",
      "[1600]\tvalidation_0-rmse:3.57648\n",
      "[1650]\tvalidation_0-rmse:3.57625\n",
      "[1700]\tvalidation_0-rmse:3.57621\n",
      "[1750]\tvalidation_0-rmse:3.5762\n",
      "[1800]\tvalidation_0-rmse:3.57591\n",
      "[1850]\tvalidation_0-rmse:3.57584\n",
      "[1900]\tvalidation_0-rmse:3.57608\n",
      "[1950]\tvalidation_0-rmse:3.57597\n",
      "[2000]\tvalidation_0-rmse:3.57606\n",
      "[2050]\tvalidation_0-rmse:3.57609\n",
      "[2100]\tvalidation_0-rmse:3.5761\n",
      "[2150]\tvalidation_0-rmse:3.57593\n",
      "[2200]\tvalidation_0-rmse:3.57588\n",
      "[2250]\tvalidation_0-rmse:3.57608\n",
      "[2300]\tvalidation_0-rmse:3.57609\n",
      "Stopping. Best iteration:\n",
      "[1848]\tvalidation_0-rmse:3.57583\n",
      "\n",
      "no 9 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.87433\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.76475\n",
      "[100]\tvalidation_0-rmse:3.69967\n",
      "[150]\tvalidation_0-rmse:3.66127\n",
      "[200]\tvalidation_0-rmse:3.63686\n",
      "[250]\tvalidation_0-rmse:3.62139\n",
      "[300]\tvalidation_0-rmse:3.6105\n",
      "[350]\tvalidation_0-rmse:3.60274\n",
      "[400]\tvalidation_0-rmse:3.59748\n",
      "[450]\tvalidation_0-rmse:3.59302\n",
      "[500]\tvalidation_0-rmse:3.59023\n",
      "[550]\tvalidation_0-rmse:3.58763\n",
      "[600]\tvalidation_0-rmse:3.58481\n",
      "[650]\tvalidation_0-rmse:3.58343\n",
      "[700]\tvalidation_0-rmse:3.58204\n",
      "[750]\tvalidation_0-rmse:3.5806\n",
      "[800]\tvalidation_0-rmse:3.5798\n",
      "[850]\tvalidation_0-rmse:3.57881\n",
      "[900]\tvalidation_0-rmse:3.57773\n",
      "[950]\tvalidation_0-rmse:3.57689\n",
      "[1000]\tvalidation_0-rmse:3.57634\n",
      "[1050]\tvalidation_0-rmse:3.57579\n",
      "[1100]\tvalidation_0-rmse:3.57535\n",
      "[1150]\tvalidation_0-rmse:3.57495\n",
      "[1200]\tvalidation_0-rmse:3.5746\n",
      "[1250]\tvalidation_0-rmse:3.57441\n",
      "[1300]\tvalidation_0-rmse:3.57439\n",
      "[1350]\tvalidation_0-rmse:3.57383\n",
      "[1400]\tvalidation_0-rmse:3.57356\n",
      "[1450]\tvalidation_0-rmse:3.57343\n",
      "[1500]\tvalidation_0-rmse:3.57341\n",
      "[1550]\tvalidation_0-rmse:3.57329\n",
      "[1600]\tvalidation_0-rmse:3.57327\n",
      "[1650]\tvalidation_0-rmse:3.57313\n",
      "[1700]\tvalidation_0-rmse:3.57297\n",
      "[1750]\tvalidation_0-rmse:3.57266\n",
      "[1800]\tvalidation_0-rmse:3.57264\n",
      "[1850]\tvalidation_0-rmse:3.57259\n",
      "[1900]\tvalidation_0-rmse:3.57226\n",
      "[1950]\tvalidation_0-rmse:3.57211\n",
      "[2000]\tvalidation_0-rmse:3.57202\n",
      "[2050]\tvalidation_0-rmse:3.57205\n",
      "[2100]\tvalidation_0-rmse:3.57215\n",
      "[2150]\tvalidation_0-rmse:3.57215\n",
      "[2200]\tvalidation_0-rmse:3.57217\n",
      "[2250]\tvalidation_0-rmse:3.5722\n",
      "[2300]\tvalidation_0-rmse:3.57229\n",
      "[2350]\tvalidation_0-rmse:3.57249\n",
      "[2400]\tvalidation_0-rmse:3.57207\n",
      "[2450]\tvalidation_0-rmse:3.57224\n",
      "[2500]\tvalidation_0-rmse:3.5724\n",
      "Stopping. Best iteration:\n",
      "[2022]\tvalidation_0-rmse:3.5718\n",
      "\n",
      "no 10 of 11 folds\n",
      "[0]\tvalidation_0-rmse:3.9193\n",
      "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
      "[50]\tvalidation_0-rmse:3.80862\n",
      "[100]\tvalidation_0-rmse:3.74396\n",
      "[150]\tvalidation_0-rmse:3.70584\n",
      "[200]\tvalidation_0-rmse:3.68209\n",
      "[250]\tvalidation_0-rmse:3.66578\n",
      "[300]\tvalidation_0-rmse:3.65474\n",
      "[350]\tvalidation_0-rmse:3.64683\n",
      "[400]\tvalidation_0-rmse:3.64099\n",
      "[450]\tvalidation_0-rmse:3.63717\n",
      "[500]\tvalidation_0-rmse:3.63449\n",
      "[550]\tvalidation_0-rmse:3.63183\n",
      "[600]\tvalidation_0-rmse:3.62917\n",
      "[650]\tvalidation_0-rmse:3.62762\n",
      "[700]\tvalidation_0-rmse:3.62603\n",
      "[750]\tvalidation_0-rmse:3.62467\n",
      "[800]\tvalidation_0-rmse:3.62319\n",
      "[850]\tvalidation_0-rmse:3.62215\n",
      "[900]\tvalidation_0-rmse:3.62133\n",
      "[950]\tvalidation_0-rmse:3.62057\n",
      "[1000]\tvalidation_0-rmse:3.6199\n",
      "[1050]\tvalidation_0-rmse:3.61912\n",
      "[1100]\tvalidation_0-rmse:3.61844\n",
      "[1150]\tvalidation_0-rmse:3.61783\n",
      "[1200]\tvalidation_0-rmse:3.61749\n",
      "[1250]\tvalidation_0-rmse:3.61677\n",
      "[1300]\tvalidation_0-rmse:3.61674\n",
      "[1350]\tvalidation_0-rmse:3.61625\n",
      "[1400]\tvalidation_0-rmse:3.61581\n",
      "[1450]\tvalidation_0-rmse:3.61583\n",
      "[1500]\tvalidation_0-rmse:3.61572\n",
      "[1550]\tvalidation_0-rmse:3.61553\n",
      "[1600]\tvalidation_0-rmse:3.6156\n",
      "[1650]\tvalidation_0-rmse:3.61561\n",
      "[1700]\tvalidation_0-rmse:3.61553\n",
      "[1750]\tvalidation_0-rmse:3.61496\n",
      "[1800]\tvalidation_0-rmse:3.61472\n",
      "[1850]\tvalidation_0-rmse:3.61457\n",
      "[1900]\tvalidation_0-rmse:3.61427\n",
      "[1950]\tvalidation_0-rmse:3.61411\n",
      "[2000]\tvalidation_0-rmse:3.61391\n",
      "[2050]\tvalidation_0-rmse:3.61385\n",
      "[2100]\tvalidation_0-rmse:3.6138\n",
      "[2150]\tvalidation_0-rmse:3.61358\n",
      "[2200]\tvalidation_0-rmse:3.6134\n",
      "[2250]\tvalidation_0-rmse:3.61327\n",
      "[2300]\tvalidation_0-rmse:3.61327\n",
      "[2350]\tvalidation_0-rmse:3.61315\n",
      "[2400]\tvalidation_0-rmse:3.61323\n",
      "[2450]\tvalidation_0-rmse:3.61326\n",
      "[2500]\tvalidation_0-rmse:3.61312\n",
      "[2550]\tvalidation_0-rmse:3.61311\n",
      "[2600]\tvalidation_0-rmse:3.61332\n",
      "[2650]\tvalidation_0-rmse:3.61339\n",
      "[2700]\tvalidation_0-rmse:3.61352\n",
      "[2750]\tvalidation_0-rmse:3.61381\n",
      "[2800]\tvalidation_0-rmse:3.61368\n",
      "[2850]\tvalidation_0-rmse:3.61386\n",
      "[2900]\tvalidation_0-rmse:3.61399\n",
      "[2950]\tvalidation_0-rmse:3.61413\n",
      "[3000]\tvalidation_0-rmse:3.61418\n",
      "Stopping. Best iteration:\n",
      "[2515]\tvalidation_0-rmse:3.61304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to subm_3.651336_XGB_cv11_2019-02-19-06-10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2019-02-19:06:12:29 <ipython-input-3-9f640adaf07c>: 45: Run LightGBM with kfold - done in 7187s\n",
      "[INFO] 2019-02-19:06:12:30 <ipython-input-3-9f640adaf07c>: 45: Full model run - done in 8588s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format='[%(levelname)s] %(asctime)s %(filename)s: %(lineno)d: %(message)s',\n",
    "    datefmt='%Y-%m-%d:%H:%M:%S',\n",
    "    level=logging.DEBUG)\n",
    "\n",
    "DATE_TODAY = dt(2019, 1, 26)\n",
    "\n",
    "FEATS_EXCLUDED = [\n",
    "    'first_active_month', 'target', 'card_id', 'outliers',\n",
    "    'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "    'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size',\n",
    "    'OOF_PRED', 'month_0']\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    logger.info(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')\n",
    "\n",
    "\n",
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "# rmse\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = df.columns.tolist()\n",
    "\n",
    "    categorical_columns = list(filter(lambda c: c in ['object'], df.dtypes))\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "\n",
    "    new_columns = list(filter(lambda c: c not in original_columns, df.columns))\n",
    "    return df, new_columns\n",
    "\n",
    "\n",
    "def process_main_df(df):\n",
    "    \n",
    "    # datetime features\n",
    "    df['quarter'] = df['first_active_month'].dt.quarter\n",
    "    df['elapsed_time'] = (DATE_TODAY - df['first_active_month']).dt.days\n",
    "\n",
    "    feature_cols = ['feature_1', 'feature_2', 'feature_3']\n",
    "    for f in feature_cols:    \n",
    "        df['days_' + f] = df['elapsed_time'] * df[f]\n",
    "        df['days_' + f + '_ratio'] = df[f] / df['elapsed_time']\n",
    "\n",
    "    # one hot encoding\n",
    "    df, cols = one_hot_encoder(df, nan_as_category=False)\n",
    "\n",
    "    df_feats = df.reindex(columns=feature_cols)\n",
    "    df['features_sum'] = df_feats.sum(axis=1)\n",
    "    df['features_mean'] = df_feats.mean(axis=1)\n",
    "    df['features_max'] = df_feats.max(axis=1)\n",
    "    df['features_min'] = df_feats.min(axis=1)\n",
    "    df['features_var'] = df_feats.std(axis=1)\n",
    "    df['features_prod'] = df_feats.product(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# preprocessing train & test\n",
    "def train_test(num_rows=None):\n",
    "\n",
    "    def read_csv(filename):\n",
    "        df = pd.read_csv(\n",
    "            filename, index_col=['card_id'], parse_dates=['first_active_month'], nrows=num_rows)\n",
    "        return df\n",
    "    \n",
    "    # load csv\n",
    "    train_df = read_csv('../input/train.csv')\n",
    "    test_df = read_csv('../input/test.csv') \n",
    "    logger.info(\"samples: train {}, test: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # outlier\n",
    "    train_df['outliers'] = 0\n",
    "    train_df.loc[train_df['target'] < -30., 'outliers'] = 1\n",
    "\n",
    "    train_df = reduce_mem_usage(process_main_df(train_df))\n",
    "    test_df = reduce_mem_usage(process_main_df(test_df))\n",
    "\n",
    "    feature_cols = ['feature_1', 'feature_2', 'feature_3']\n",
    "    for f in feature_cols:\n",
    "        order_label = train_df.groupby([f])['outliers'].mean()\n",
    "        train_df[f] = train_df[f].map(order_label)\n",
    "        test_df[f] = test_df[f].map(order_label)    \n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def process_date(df):\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['day'] = df['purchase_date'].dt.day\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['weekday'] = df['purchase_date'].dt.weekday\n",
    "    df['weekend'] = (df['purchase_date'].dt.weekday >= 5).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dist_holiday(df, col_name, date_holiday, date_ref, period=100):\n",
    "    df[col_name] = np.maximum(np.minimum((pd.to_datetime(date_holiday) - df[date_ref]).dt.days, period), 0)\n",
    "\n",
    "\n",
    "def historical_transactions(num_rows=None):\n",
    "    \"\"\"\n",
    "    preprocessing historical transactions\n",
    "    \"\"\"\n",
    "    na_dict = {\n",
    "        'category_2': 1.,\n",
    "        'category_3': 'A',\n",
    "        'merchant_id': 'M_ID_00a6ca8a8a',\n",
    "    }\n",
    "\n",
    "    holidays = [\n",
    "        ('Christmas_Day_2017', '2017-12-25'),  # Christmas: December 25 2017\n",
    "        ('Mothers_Day_2017', '2017-06-04'),  # Mothers Day: May 14 2017\n",
    "        ('fathers_day_2017', '2017-08-13'),  # fathers day: August 13 2017\n",
    "        ('Children_day_2017', '2017-10-12'),  # Childrens day: October 12 2017\n",
    "        ('Valentine_Day_2017', '2017-06-12'),  # Valentine's Day : 12th June, 2017\n",
    "        ('Black_Friday_2017', '2017-11-24'),  # Black Friday: 24th November 2017\n",
    "        ('Mothers_Day_2018', '2018-05-13'),\n",
    "    ]\n",
    "\n",
    "    # agg\n",
    "    aggs = dict()\n",
    "    col_unique = ['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    aggs.update({col: ['nunique'] for col in col_unique})\n",
    "\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "    aggs.update({col: ['nunique', 'mean', 'min', 'max'] for col in col_seas})\n",
    "\n",
    "    aggs_specific = {\n",
    "        'purchase_amount': ['sum', 'max', 'min', 'mean', 'var', 'skew'],\n",
    "        'installments': ['sum', 'max', 'mean', 'var', 'skew'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'month_lag': ['max', 'min', 'mean', 'var', 'skew'],\n",
    "        'month_diff': ['max', 'min', 'mean', 'var', 'skew'],\n",
    "        'authorized_flag': ['mean'],\n",
    "        'weekend': ['mean'], # overwrite\n",
    "        'weekday': ['mean'], # overwrite\n",
    "        'day': ['nunique', 'mean', 'min'], # overwrite\n",
    "        'category_1': ['mean'],\n",
    "        'category_2': ['mean'],\n",
    "        'category_3': ['mean'],\n",
    "        'card_id': ['size', 'count'],\n",
    "        'price': ['sum', 'mean', 'max', 'min', 'var'],\n",
    "        'Christmas_Day_2017': ['mean', 'sum'],\n",
    "        'Mothers_Day_2017': ['mean', 'sum'],\n",
    "        'fathers_day_2017': ['mean', 'sum'],\n",
    "        'Children_day_2017': ['mean', 'sum'],\n",
    "        'Valentine_Day_2017': ['mean', 'sum'],\n",
    "        'Black_Friday_2017': ['mean', 'sum'],\n",
    "        'Mothers_Day_2018': ['mean', 'sum'],\n",
    "        'duration': ['mean', 'min', 'max', 'var', 'skew'],\n",
    "        'amount_month_ratio': ['mean', 'min', 'max', 'var', 'skew'],\n",
    "    }\n",
    "    aggs.update(aggs_specific)\n",
    "\n",
    "    # starting to process\n",
    "    # load csv\n",
    "    df = pd.read_csv('../input/historical_transactions.csv', nrows=num_rows)\n",
    "    logger.info('read historical_transactions {}'.format(df.shape))\n",
    "    \n",
    "    # fillna\n",
    "    df.fillna(na_dict, inplace=True)\n",
    "    df['installments'].replace({\n",
    "        -1: np.nan, 999: np.nan}, inplace=True)\n",
    "\n",
    "    # trim\n",
    "    df['purchase_amount'] = df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(np.int16)\n",
    "    df['category_1'] = df['category_1'].map({'Y': 1, 'N': 0}).astype(np.int16)\n",
    "    df['category_3'] = df['category_3'].map({'A': 0, 'B': 1, 'C':2}).astype(np.int16)\n",
    "\n",
    "    # additional features\n",
    "    df['price'] = df['purchase_amount'] / df['installments']\n",
    "\n",
    "    # datetime features\n",
    "    df = process_date(df)\n",
    "\n",
    "    # holidays\n",
    "    for d_name, d_day in holidays:\n",
    "        dist_holiday(df, d_name, d_day, 'purchase_date')\n",
    "\n",
    "    df['month_diff'] = (DATE_TODAY - df['purchase_date']).dt.days // 30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    df['duration'] = df['purchase_amount'] * df['month_diff']\n",
    "    df['amount_month_ratio'] = df['purchase_amount'] / df['month_diff']\n",
    "\n",
    "    # reduce memory usage\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    for col in ['category_2', 'category_3']:\n",
    "        df[col + '_mean'] = df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        df[col + '_min'] = df.groupby([col])['purchase_amount'].transform('min')\n",
    "        df[col + '_max'] = df.groupby([col])['purchase_amount'].transform('max')\n",
    "        df[col + '_sum'] = df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col + '_mean'] = ['mean']\n",
    "    \n",
    "    df = df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    df.columns = pd.Index([e[0] + \"_\" + e[1] for e in df.columns.tolist()])\n",
    "    df.columns = ['hist_' + c for c in df.columns]\n",
    "\n",
    "    df['hist_CLV'] = df['hist_card_id_count'] * df['hist_purchase_amount_sum'] / df['hist_month_diff_mean']\n",
    "\n",
    "    df['hist_purchase_date_diff'] = (df['hist_purchase_date_max'] - df['hist_purchase_date_min']).dt.days\n",
    "    df['hist_purchase_date_average'] = df['hist_purchase_date_diff'] / df['hist_card_id_size']\n",
    "    df['hist_purchase_date_uptonow'] = (DATE_TODAY - df['hist_purchase_date_max']).dt.days\n",
    "    df['hist_purchase_date_uptomin'] = (DATE_TODAY - df['hist_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def new_merchant_transactions(num_rows=None):\n",
    "    \"\"\"\n",
    "    preprocessing new_merchant_transactions\n",
    "    \"\"\"\n",
    "    na_dict = {\n",
    "        'category_2': 1.,\n",
    "        'category_3': 'A',\n",
    "        'merchant_id': 'M_ID_00a6ca8a8a',\n",
    "    }\n",
    "\n",
    "    holidays = [\n",
    "        ('Christmas_Day_2017', '2017-12-25'),  # Christmas: December 25 2017\n",
    "        # ('Mothers_Day_2017', '2017-06-04'),  # Mothers Day: May 14 2017\n",
    "        # ('fathers_day_2017', '2017-08-13'),  # fathers day: August 13 2017\n",
    "        ('Children_day_2017', '2017-10-12'),  # Childrens day: October 12 2017\n",
    "        # ('Valentine_Day_2017', '2017-06-12'),  # Valentine's Day : 12th June, 2017\n",
    "        ('Black_Friday_2017', '2017-11-24'),  # Black Friday: 24th November 2017\n",
    "        ('Mothers_Day_2018', '2018-05-13'),\n",
    "    ]\n",
    "    \n",
    "    aggs = dict()\n",
    "    col_unique = ['subsector_id', 'merchant_id', 'merchant_category_id']\n",
    "    aggs.update({col: ['nunique'] for col in col_unique})\n",
    "\n",
    "    col_seas = ['month', 'hour', 'weekofyear', 'weekday', 'day']\n",
    "    aggs.update({col: ['nunique', 'mean', 'min', 'max'] for col in col_seas})\n",
    "\n",
    "    aggs_specific = {\n",
    "        'purchase_amount': ['sum', 'max', 'min', 'mean', 'var', 'skew'],\n",
    "        'installments': ['sum', 'max', 'mean', 'var', 'skew'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'month_lag': ['max', 'min', 'mean', 'var', 'skew'],\n",
    "        'month_diff': ['mean', 'var', 'skew'],\n",
    "        'weekend': ['mean'],\n",
    "        'month': ['mean', 'min', 'max'],\n",
    "        'weekday': ['mean', 'min', 'max'],\n",
    "        'category_1': ['mean'],\n",
    "        'category_2': ['mean'],\n",
    "        'category_3': ['mean'],\n",
    "        'card_id': ['size', 'count'],\n",
    "        'price': ['mean', 'max', 'min', 'var'],\n",
    "        'Christmas_Day_2017': ['mean', 'sum'],\n",
    "        'Children_day_2017': ['mean', 'sum'],\n",
    "        'Black_Friday_2017': ['mean', 'sum'],\n",
    "        'Mothers_Day_2018': ['mean', 'sum'],\n",
    "        'duration': ['mean', 'min', 'max', 'var', 'skew'],\n",
    "        'amount_month_ratio': ['mean', 'min', 'max', 'var', 'skew'],\n",
    "    }\n",
    "    aggs.update(aggs_specific)\n",
    "\n",
    "    # load csv\n",
    "    df = pd.read_csv('../input/new_merchant_transactions.csv', nrows=num_rows)\n",
    "    logger.info('read new_merchant_transactions {}'.format(df.shape))\n",
    "    \n",
    "    # fillna\n",
    "    df.fillna(na_dict, inplace=True)\n",
    "    df['installments'].replace({\n",
    "        -1: np.nan, 999: np.nan}, inplace=True)\n",
    "\n",
    "    # trim\n",
    "    df['purchase_amount'] = df['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    # Y/N to 1/0\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int).astype(np.int16)\n",
    "    df['category_1'] = df['category_1'].map({'Y': 1, 'N': 0}).astype(int).astype(np.int16)\n",
    "    df['category_3'] = df['category_3'].map({'A': 0, 'B': 1, 'C': 2}).astype(int).astype(np.int16)\n",
    "\n",
    "    # additional features\n",
    "    df['price'] = df['purchase_amount'] / df['installments']\n",
    "\n",
    "    # datetime features\n",
    "    df = process_date(df)\n",
    "    for d_name, d_day in holidays:\n",
    "        dist_holiday(df, d_name, d_day, 'purchase_date')\n",
    "\n",
    "    df['month_diff'] = (DATE_TODAY - df['purchase_date']).dt.days // 30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "\n",
    "    # additional features\n",
    "    df['duration'] = df['purchase_amount'] * df['month_diff']\n",
    "    df['amount_month_ratio'] = df['purchase_amount'] / df['month_diff']\n",
    "\n",
    "    # reduce memory usage\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    for col in ['category_2', 'category_3']:\n",
    "        df[col+'_mean'] = df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        df[col+'_min'] = df.groupby([col])['purchase_amount'].transform('min')\n",
    "        df[col+'_max'] = df.groupby([col])['purchase_amount'].transform('max')\n",
    "        df[col+'_sum'] = df.groupby([col])['purchase_amount'].transform('sum')\n",
    "        aggs[col + '_mean'] = ['mean']\n",
    "\n",
    "    df = df.reset_index().groupby('card_id').agg(aggs)\n",
    "\n",
    "    # change column name\n",
    "    df.columns = pd.Index([e[0] + \"_\" + e[1] for e in df.columns.tolist()])\n",
    "    df.columns = ['new_' + c for c in df.columns]\n",
    "\n",
    "    df['new_CLV'] = df['new_card_id_count'] * df['new_purchase_amount_sum'] / df['new_month_diff_mean']\n",
    "    \n",
    "    df['new_purchase_date_diff'] = (df['new_purchase_date_max'] - df['new_purchase_date_min']).dt.days\n",
    "    df['new_purchase_date_average'] = df['new_purchase_date_diff'] / df['new_card_id_size']\n",
    "    df['new_purchase_date_uptonow'] = (DATE_TODAY - df['new_purchase_date_max']).dt.days\n",
    "    df['new_purchase_date_uptomin'] = (DATE_TODAY - df['new_purchase_date_min']).dt.days\n",
    "\n",
    "    # reduce memory usage\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    return df\n",
    "        \n",
    "\n",
    "# additional features\n",
    "def additional_features(df):\n",
    "    \n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['hist_last_buy'] = (df['hist_purchase_date_max'] - df['first_active_month']).dt.days\n",
    "\n",
    "    df['new_first_buy'] = (df['new_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_last_buy'] = (df['new_purchase_date_max'] - df['first_active_month']).dt.days\n",
    "\n",
    "    date_features = [\n",
    "        'hist_purchase_date_max', 'hist_purchase_date_min', 'new_purchase_date_max', 'new_purchase_date_min']\n",
    "    for f in date_features:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "\n",
    "    #\n",
    "    df['card_id_total'] = df['new_card_id_size'] + df['hist_card_id_size']\n",
    "    df['card_id_cnt_total'] = df['new_card_id_count'] + df['hist_card_id_count']\n",
    "    df['card_id_cnt_ratio'] = df['new_card_id_count'] / df['hist_card_id_count']\n",
    "    \n",
    "    df['purchase_amount_total'] = df['new_purchase_amount_sum'] + df['hist_purchase_amount_sum']\n",
    "    df['purchase_amount_mean'] = df['new_purchase_amount_mean'] + df['hist_purchase_amount_mean']\n",
    "    df['purchase_amount_max'] = df['new_purchase_amount_max'] + df['hist_purchase_amount_max']\n",
    "    df['purchase_amount_min'] = df['new_purchase_amount_min'] + df['hist_purchase_amount_min']\n",
    "    df['purchase_amount_ratio'] = df['new_purchase_amount_sum'] / df['hist_purchase_amount_sum']\n",
    "\n",
    "    df['installments_total'] = df['new_installments_sum'] + df['hist_installments_sum']\n",
    "    df['installments_mean'] = df['new_installments_mean'] + df['hist_installments_mean']\n",
    "    df['installments_max'] = df['new_installments_max'] + df['hist_installments_max']\n",
    "    df['installments_ratio'] = df['new_installments_sum'] / df['hist_installments_sum']\n",
    "\n",
    "    df['price_total'] = df['purchase_amount_total'] / df['installments_total']\n",
    "    df['price_mean'] = df['purchase_amount_mean'] / df['installments_mean']\n",
    "    df['price_max'] = df['purchase_amount_max'] / df['installments_max']\n",
    "\n",
    "    #\n",
    "    df['month_diff_mean'] = df['new_month_diff_mean'] + df['hist_month_diff_mean']\n",
    "    df['month_diff_ratio'] = df['new_month_diff_mean'] / df['hist_month_diff_mean']\n",
    "    \n",
    "    df['month_lag_mean'] = df['new_month_lag_mean'] + df['hist_month_lag_mean']\n",
    "    df['month_lag_max'] = df['new_month_lag_max'] + df['hist_month_lag_max']\n",
    "    df['month_lag_min'] = df['new_month_lag_min'] + df['hist_month_lag_min']\n",
    "    df['category_1_mean'] = df['new_category_1_mean'] + df['hist_category_1_mean']\n",
    "        \n",
    "    df['duration_mean'] = df['new_duration_mean'] + df['hist_duration_mean']\n",
    "    df['duration_min'] = df['new_duration_min'] + df['hist_duration_min']\n",
    "    df['duration_max'] = df['new_duration_max'] + df['hist_duration_max']\n",
    "    \n",
    "    df['amount_month_ratio_mean'] = df['new_amount_month_ratio_mean'] + df['hist_amount_month_ratio_mean']\n",
    "    df['amount_month_ratio_min'] = df['new_amount_month_ratio_min'] + df['hist_amount_month_ratio_min']\n",
    "    df['amount_month_ratio_max'] = df['new_amount_month_ratio_max'] + df['hist_amount_month_ratio_max']\n",
    "    \n",
    "    df['CLV_ratio'] = df['new_CLV'] / df['hist_CLV']\n",
    "    df['CLV_sq'] = df['new_CLV'] * df['hist_CLV']\n",
    "\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def modeling_xgb_cross_validation(params, X, y, nr_folds=5, verbose=0):\n",
    "    clfs = list()\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    # Split data with kfold\n",
    "    #kfolds = TimeSeriesSplit(n_splits=nr_folds)\n",
    "    kfolds = StratifiedKFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    split_index = X[['feature_1', 'feature_2', 'feature_3']].apply(lambda x: np.log1p(x)).product(axis=1)\n",
    "    kfolds = KFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, split_index)):\n",
    "        if verbose:\n",
    "            print('no {} of {} folds'.format(n_fold, nr_folds))\n",
    "\n",
    "        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            # eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=verbose, eval_metric='rmse',\n",
    "            early_stopping_rounds=500\n",
    "        )\n",
    "\n",
    "        clfs.append(model)\n",
    "        oof_preds[val_idx] = model.predict(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        del X_train, y_train, X_valid, y_valid\n",
    "        gc.collect()\n",
    "\n",
    "    score = mean_squared_error(y, oof_preds) ** .5\n",
    "    return clfs, score\n",
    "\n",
    "\n",
    "def modeling_lgbm_cross_validation(params, X, y, nr_folds=5, verbose=0):\n",
    "    clfs = list()\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    # Split data with kfold\n",
    "    # kfolds = TimeSeriesSplit(n_splits=nr_folds)\n",
    "    kfolds = StratifiedKFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    split_index = X[['feature_1', 'feature_2', 'feature_3']].apply(lambda x: np.log1p(x)).product(axis=1)\n",
    "    kfolds = KFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "        if verbose:\n",
    "            print('no {} of {} folds'.format(n_fold, nr_folds))\n",
    "\n",
    "        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            # eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=verbose, eval_metric='rmse',\n",
    "            early_stopping_rounds=500\n",
    "        )\n",
    "\n",
    "        clfs.append(model)\n",
    "        oof_preds[val_idx] = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "\n",
    "        del X_train, y_train, X_valid, y_valid\n",
    "        gc.collect()\n",
    "\n",
    "    score = mean_squared_error(y, oof_preds) ** .5\n",
    "    return clfs, score\n",
    "\n",
    "\n",
    "def predict_cross_validation(test, clfs, ntree_limit=None):\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    for i, model in enumerate(clfs, 1):\n",
    "\n",
    "        num_tree = 10000\n",
    "        if not ntree_limit:\n",
    "            ntree_limit = num_tree\n",
    "\n",
    "        if isinstance(model, lgb.sklearn.LGBMRegressor):\n",
    "            if model.best_iteration_:\n",
    "                num_tree = min(ntree_limit, model.best_iteration_)\n",
    "\n",
    "            test_preds = model.predict(test, raw_score=True, num_iteration=num_tree)\n",
    "\n",
    "        if isinstance(model, xgb.sklearn.XGBRegressor):\n",
    "            num_tree = min(ntree_limit, model.best_ntree_limit)\n",
    "            test_preds = model.predict(test, ntree_limit=num_tree)\n",
    "\n",
    "        sub_preds += test_preds\n",
    "\n",
    "    sub_preds = sub_preds / len(clfs)\n",
    "    ret = pd.Series(sub_preds, index=test.index)\n",
    "    ret.index.name = test.index.name\n",
    "    return ret\n",
    "\n",
    "\n",
    "def write_to_parquet(filename, df, debug=False):\n",
    "    print('write to {}: {}'.format(filename, df.shape))\n",
    "\n",
    "    # safety check\n",
    "    cols_type = df.dtypes.to_dict()\n",
    "    for col, col_type in cols_type.items():\n",
    "        if str(col_type).startswith('float16'):\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    df.to_parquet(filename, engine='auto', compression='snappy')\n",
    "    if debug:\n",
    "        df = pd.read_parquet(filename)\n",
    "        print('debug reload save file: {}\\n{}'.format(df.shape, df.head().T))\n",
    "\n",
    "\n",
    "def main(debug=False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    \n",
    "    with timer(\"historical transactions\"):\n",
    "        hist_df = historical_transactions(num_rows)\n",
    "        \n",
    "    with timer(\"new merchants\"):\n",
    "        new_merchant_df = new_merchant_transactions(num_rows)\n",
    "        \n",
    "    with timer(\"additional features\"):\n",
    "        df = pd.concat([new_merchant_df, hist_df], axis=1)\n",
    "        del new_merchant_df, hist_df\n",
    "        gc.collect()\n",
    "\n",
    "        train_df, test_df = train_test(num_rows)\n",
    "        train_df = train_df.join(df, how='left', on='card_id')\n",
    "        test_df = test_df.join(df, how='left', on='card_id')\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "        train_df = additional_features(train_df)\n",
    "        test_df = additional_features(test_df)\n",
    "               \n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        excluded_features = FEATS_EXCLUDED\n",
    "        train_features = [c for c in train_df.columns if c not in excluded_features]\n",
    "        best_params = {\n",
    "            'gpu_id': 0, \n",
    "            #'n_gpus': 2, \n",
    "            'objective': 'reg:linear', \n",
    "            'eval_metric': 'rmse', \n",
    "            'silent': True, \n",
    "            'booster': 'gbtree', \n",
    "            'n_jobs': 4, \n",
    "            'n_estimators': 2500, \n",
    "            'tree_method': 'gpu_hist', \n",
    "            'grow_policy': 'lossguide', \n",
    "            'max_depth': 12, \n",
    "            'seed': 538, \n",
    "            'colsample_bylevel': 0.9, \n",
    "            'colsample_bytree': 0.8, \n",
    "            'gamma': 0.0001, \n",
    "            'learning_rate': 0.006150886706231842, \n",
    "            'max_bin': 128, \n",
    "            'max_leaves': 47, \n",
    "            'min_child_weight': 40, \n",
    "            'reg_alpha': 10.0, \n",
    "            'reg_lambda': 10.0, \n",
    "            'subsample': 0.9}\n",
    "\n",
    "        # modeling\n",
    "        nr_folds = 11\n",
    "        if debug:\n",
    "            nr_folds = 2\n",
    "        best_params.update({'n_estimators': 20000})\n",
    "        clfs = list()\n",
    "        score = 0\n",
    "        clfs, score = modeling_xgb_cross_validation(best_params,\n",
    "                                                    train_df[train_features],\n",
    "                                                    train_df['target'],\n",
    "                                                    nr_folds,\n",
    "                                                    verbose=50)\n",
    "        # save to\n",
    "        file_template = '{score:.6f}_{model_key}_cv{fold}_{timestamp}'\n",
    "        file_stem = file_template.format(\n",
    "            score=score,\n",
    "            model_key='XGB',\n",
    "            fold=nr_folds,\n",
    "            timestamp=dt.now().strftime('%Y-%m-%d-%H-%M'))\n",
    "\n",
    "        filename = 'subm_{}.csv'.format(file_stem)\n",
    "        print('save to {}'.format(filename))\n",
    "        subm = predict_cross_validation(test_df[train_features], clfs)\n",
    "        subm = subm.to_frame('target')\n",
    "        subm.to_csv(filename, index=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with timer(\"Full model run\"):\n",
    "        main(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "429d76240d76ed67257e111ee957a00e438ce685"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e9cdd9e5263d9bc2ad04d2230591cf6889280c95"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
