{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скоринг Авто Кредиты - учебный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем скоринг. Удалил все малоинформативные и не до конца понятные мне столбцы. Не стал обращать внимание на статусы кредитов (Одобрен, отказан и так далее). Так гораздо больше данных для обучения модели. Просрочку считаем как максимум между просрочкой ОД и %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Таргет** - плохих клиентов определил двумя способами. \n",
    "- Клиенты, которые вышли на просрочку 60+\n",
    "- Клиенты, допустившие просрочку 3 месяца подряд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# подгружаем все нужные пакеты\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# игнорируем warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "%matplotlib inline\n",
    "\n",
    "# настройка внешнего вида графиков в seaborn\n",
    "sns.set_context(\n",
    "    \"notebook\", \n",
    "    font_scale = 1.5,       \n",
    "    rc = { \n",
    "        \"figure.figsize\" : (30, 30), \n",
    "        \"axes.titlesize\" : 18 \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('auto_app.csv', delimiter=\";\",decimal=\".\", encoding=\"windows-1251\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как признаки коррелируют между собой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,50))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки с сильной корреляцией (свыше 0.6, менее -0.6 тоже) необходимо будет дополнительно проанализировать и удалить в случае необходимости.\n",
    "\n",
    "Удалим ИИН. Порядковый номер тоже удалим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iin = data['IIN']\n",
    "data = data.drop(('IIN'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[[0,1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим числовые и категориальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_columns = [c for c in data.columns if data[c].dtype.name == 'object']\n",
    "numerical_columns   = [c for c in data.columns if data[c].dtype.name != 'object']\n",
    "print (categorical_columns)\n",
    "print (numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[categorical_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[numerical_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.count(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего у нас 17433. Попробуем разнные техники заполнения пустых значений. Возьмем для примера признак ПОЛ - заполним пропуски самым часто встречаемым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Пол'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Пол'] = data['Пол'].fillna('Мужской')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[categorical_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним для начала пропуски в определенных столбцах самыми часто встречаемыми значениями. Везде количество должно быть 17433. Если в столбце не хватает 40% или более данных, такой столбец можно удалять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(data[categorical_columns].count(axis=0)/data.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop((['Статус занятости.1','Категория занимаемой должности','Тип платежа']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_describe = data.describe(include=[object])\n",
    "for c in ['Гражданство','Резиденство','Образование','Семейное положение',\\\n",
    "          'Адрес фактического проживания совпадает с адресом регистрации?','Отношение к месту проживания', \\\n",
    "          'Филиал', 'СПФ','Канал продаж'\n",
    "         ]:\n",
    "    data[c] = data[c].fillna(data_describe[c]['top'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не трогаем поле **Агент**, из него мы сделаем позднее производное поле. Поле **Должность клиента** и **Вид деятельности компании/организации** потеряют очень много в информативности, если заменить часто встречаемым. Не могут все быть только Директорами. Поэтому удалим. Остальные заполним частовстречаемым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop((['Должность клиента','Вид деятельности компании/организации']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_columns = [c for c in data.columns if data[c].dtype.name == 'object']\n",
    "print (categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(data[categorical_columns].count(axis=0)/data.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на остальные с пропущенными данными более детально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['Цель кредитования','Условия кредитования','Наименование атосалона',\\\n",
    "      'Схема финансирования','Вид страхования','Категория клиента','Статус занятости','Имеется работа по совместительству?',\\\n",
    "     'Являетесь ли вы лицом, освобожденным от уплаты обязательных пенсионных взносов в НПФ',\\\n",
    "     'Кредитная история в БВУ (автомат)','Кредитная история в БВУ (А0)']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_describe = data.describe(include=[object])\n",
    "for c in ['Цель кредитования','Условия кредитования','Наименование атосалона',\\\n",
    "          'Схема финансирования','Вид страхования','Категория клиента',\\\n",
    "          'Статус занятости','Имеется работа по совместительству?',\\\n",
    "          'Являетесь ли вы лицом, освобожденным от уплаты обязательных пенсионных взносов в НПФ'\n",
    "         ]:\n",
    "    data[c] = data[c].fillna(data_describe[c]['top'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока не трогаем поле **Кредитная история в БВУ**. Самое часто встречаемое там **Безупречная**. Плосмотрим какие еще значения там есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Кредитная история в БВУ (автомат)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Кредитная история в БВУ (А0)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не верно говорить, что у всех у кого пустые данные поля Кредитная история Безупречная. Будем счиатать, что она **Отсутствует**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in ['Кредитная история в БВУ (автомат)', 'Кредитная история в БВУ (А0)']:\n",
    "    data[c] = data[c].fillna('Отсутствует')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(data[categorical_columns].count(axis=0)/data.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим еще раз на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_columns = [c for c in data.columns if data[c].dtype.name == 'object']\n",
    "print (categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[categorical_columns].count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[numerical_columns].count(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только в поле **Агент** остались пропуски. Займемся этим позднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале выделим бинарные и небинарные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_columns    = [c for c in categorical_columns if data_describe[c]['unique'] == 2]\n",
    "nonbinary_columns = [c for c in categorical_columns if data_describe[c]['unique'] > 2]\n",
    "print (binary_columns, nonbinary_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бинарные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения бинарных признаков просто заменим на 0 и 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in binary_columns[0:]:\n",
    "    top = data_describe[c]['top']\n",
    "    top_items = data[c] == top\n",
    "    data.loc[top_items, c] = 1\n",
    "    data.loc[np.logical_not(top_items), c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[binary_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небинарные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonbinary_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[nonbinary_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поля: **Кредитная история в БВУ (А0), Кредитная история в БВУ (автомат), Статус занятости, Категория клиента,Цель кредитования,Семейное положение** мы будем кодировать методом векторизации, который заключается в следующем.\n",
    "\n",
    "Признак j, принимающий s значений, заменим на s признаков, принимащих значения 0 или 1, в зависимости от того, чему равно значение исходного признака j.\n",
    "\n",
    "Например, признак A4 принимает 3 различных значения 'u', 'y', 'l'\n",
    "    \n",
    "Заменим признак A4 тремя признаками: A4_u, A4_y, A4_l.\n",
    "\n",
    "- Если признак A4 принимает значение u, то признак A4_u равен 1, A4_y равен 0, A4_l равен 0.\n",
    "- Если признак A4 принимает значение y, то признак A4_y равен 0, A4_y равен 1, A4_l равен 0.\n",
    "- Если признак A4 принимает значение l, то признак A4_l равен 0, A4_y равен 0, A4_l равен 1.\n",
    "\n",
    "К остальным мы этот метод не применяем, так как они содержат слишком много уникальных значения, для них примененим другой метод, что бы не потерять информативность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dummies = pd.get_dummies(data[['Кредитная история в БВУ (А0)',\\\n",
    "                                   'Кредитная история в БВУ (автомат)', 'Статус занятости',\\\n",
    "                                   'Категория клиента',\\\n",
    "                                   'Цель кредитования','Семейное положение']])\n",
    "print(data_dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, остались признаки:'Гражданство', 'Образование', 'Отношение к месту проживания', 'Филиал', 'СПФ', 'Канал продаж',\n",
    " 'Агент', 'Условия кредитования', 'Наименование атосалона'. Признак 'Агент' все так же не трогаем. В остальных признаках много значений, будем их кодировтаь средним.\n",
    "Закодировав средними мы не потеряем информативность. Мы будем кодировать все признаки кроме 'Агент' средним от **target** таким образом мы поймем, например, по какому филиалу больше с среднем клиентов с просрочкой.\n",
    "\n",
    "Можно это делать так же по другим параметрам. Наример по **Запрошенной сумме кредита**, тогда поймем где больше у нас запрашивают кредитов в среднем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Гражданство_mean'] = data.groupby(['Гражданство'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Образование_mean'] = data.groupby(['Образование'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Отношение к месту проживания_mean'] = data.groupby(['Отношение к месту проживания'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Филиал_mean'] = data.groupby(['Филиал'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['СПФ_mean'] = data.groupby(['СПФ'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Канал продаж_mean'] = data.groupby(['Канал продаж'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Условия кредитования_mean'] = data.groupby(['Условия кредитования'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Наименование атосалона_mean'] = data.groupby(['Наименование атосалона'])['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop((['Гражданство', 'Образование', 'Отношение к месту проживания', 'Филиал', 'СПФ', 'Канал продаж',\\\n",
    "                   'Условия кредитования', 'Наименование атосалона']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признак Агент закодируем следующим образом, если оно не пустое напишем в новом поле 1, если пустое 0. Таким образом мы будем знать, что это поле было либо пустое, либо там был какой то агент. Отсутствие информации - тоже информация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Агент'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['Агент'].notnull(), 'Агент_new'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['Агент'].isnull(), 'Агент_new'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Агент_new'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Агент_new'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соединяем все в одну таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_columns   = [c for c in data.columns if data[c].dtype.name != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_numerical = data[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat((data_numerical, data_dummies, data[binary_columns]), axis=1)\n",
    "data = pd.DataFrame(data, dtype=float)\n",
    "print (data.shape, data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы сделали очень много разных манипуляций с нашими данными. Полезно снова взглянуть на корреляцию. Графически это выгледело не слишком привлекательно и понятно. Поэтому взглянем в виде текста. Вывожу первых 60 пар."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Наибольшая корреляция:\")\n",
    "print(get_top_abs_correlations(data, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что очень многие признаки коррелирует очень сильно дург с другом и корреляция в ряде случаев почти равна 1. Это говорит о том, что либо признаки одинаковы либо очень линейно зависимы. Я удалю те, которые справа и выше 0.7 (В бою я б конечно обсудил бы это с экспертом). Если посмотреть внимательно, присутсвует и мультиколлениарность, то есть зависимость одного признака от нескольких."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop((['Коэффициент О/Д (автомат)', 'СПФ_mean', 'ВСЕГО совокупный расход', 'Статус занятости_Трудовой договор без срока (постоянная занятость)'\\\n",
    "                   ,'Кредитная история в БВУ (автомат)_Безупречная', 'Кредитная история в БВУ (автомат)_Положительная',\\\n",
    "                    'Всего совокупный доход Заемщика и Созаемщика','Комиссиия за рассмотрение кредитной заявки',\\\n",
    "                    'Оценочная стоимость по данным НОК', 'По основному месту работы/доходы от основной предпринимательской деятельности',\\\n",
    "                    'Первоначальный взнос','Категория клиента_Зарплатный проект',\\\n",
    "                   'Цель кредитования_Приобретение нового автотранспорта в автосалоне-партнере (государственная программа по поддержке отечественных автопроизводителей)'\\\n",
    "                   ,'Семейное положение_холост/незамужем','Комиссия за зачисление средств на счета физических лиц',\\\n",
    "                    'Кредитная история в БВУ (А0)_Отсутствует','Всего совокупный доход Заемщика и Созаемщика','Среднемесячный доход, подтвержденный ГЦВП (А0)',\\\n",
    "                    'Коэффициент О/Д (А0)','Еж.платежи в БВУ (А0)','Сумма ежемесячного платежа','Метод принятия решения','Переплата по кредиту',\\\n",
    "                    'Всего совокупный доход Заемщика и Созаемщика','Кредитная история в БВУ (автомат)_Отсутствует',\\\n",
    "                    'Процентная ставка']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее мы создадим отдельный вектор y с выходной (целевой) признак - ответом и удалим его из таблицы с данными для обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['target']\n",
    "data = data.drop(('target'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая и тестовая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('creditNumber', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size = 0.3, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "print (N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(24/12179)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(17/5213)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((17+24)/(12179+5213))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что выборка несбалансированная - 0.23% плохих кредитов. Этого мало для качественного обучения модели. В таких ситуациях можно поступить двумя вариантам. Первый - увеличить количество плохих в выборке. Второй уменьшитть количество хороших. Этот метод называет АндерСэмплирование. Производится случайным образом. Сделаем, что бы доля стала хотя бы 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = {0: 369, 1: 41}\n",
    "rus = RandomUnderSampler(random_state=42,ratio=ratio)\n",
    "X_res, y_res = rus.fit_sample(data, y)\n",
    "print('Размер нового датасета %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pie(y):\n",
    "    target_stats = Counter(y)\n",
    "    labels = list(target_stats.keys())\n",
    "    sizes = list(target_stats.values())\n",
    "    explode = tuple([0.1] * len(target_stats))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, explode=explode, labels=labels, shadow=True,\n",
    "           autopct='%1.1f%%')\n",
    "    ax.axis('equal')\n",
    "plot_pie(y_res)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(X_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем numpy.ndarray в DataFrame и в Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_n = pd.DataFrame(X_res, columns=list(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame(y_res,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_Series = df_y.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_n, y_Series, test_size = 0.3, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_train, _ = X_train.shape \n",
    "N_test,  _ = X_test.shape \n",
    "print (N_train, N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(28/287)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(13/123)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((30+11)/(287+123))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest – случайный леc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем GridSearchCV для подбора лучших параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='entropy', \n",
    "                             n_estimators=50,\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_train = np.mean(y_train != rf.predict(X_train))\n",
    "err_test  = np.mean(y_test  != rf.predict(X_test))\n",
    "print (err_train, err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмторим на значимые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat((pd.DataFrame(data.columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = X_train.columns\n",
    "d_first = 40\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.title(\"Важные признаки для определения просрочника\")\n",
    "plt.bar(range(d_first), importances[indices[:d_first]], align='center')\n",
    "plt.xticks(range(d_first), np.array(feature_names)[indices[:d_first]], rotation=90)\n",
    "plt.xlim([-1, d_first]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность и полнота\n",
    "\n",
    "Точность (precision) и полнота (recall) являются метриками которые используются при оценке большей части алгоритмов извлечения информации. Иногда они используются сами по себе, иногда в качестве базиса для производных метрик, таких как F-мера или R-Precision. Суть точности и полноты очень проста.\n",
    "\n",
    "Точность системы в пределах класса – это доля документов действительно принадлежащих данному классу относительно всех документов которые система отнесла к этому классу. Полнота системы – это доля найденных классфикатором документов принадлежащих классу относительно всех документов этого класса в тестовой выборке.\n",
    "\n",
    "Эти значения легко рассчитать на основании таблицы контингентности, которая составляется для каждого класса отдельно.\n",
    "В таблице содержится информация сколько раз система приняла верное и сколько раз неверное решение по документам заданного класса. А именно:\n",
    "\n",
    "TP — истино-положительное решение;\n",
    "TN — истино-отрицательное решение;\n",
    "FP — ложно-положительное решение;\n",
    "FN — ложно-отрицательное решение.\n",
    "\n",
    "Тогда, точность и полнота определяются следующим образом:\n",
    "Precision=TP/(TP+FP)\n",
    "Recall=TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Рассмотрим пример. Допустим, у вас есть тестовая выборка в которой 10 сообщений, из них 4 – спам. Обработав все сообщения классификатор пометил 2 сообщения как спам, причем одно действительно является спамом, а второе было помечено в тестовой выборке как нормальное. Мы имеем одно истино-положительное решение, три ложно-отрицательных и одно ложно-положительное. Тогда для класса “спам” точность классификатора составляет 12 (50% положительных решений правильные), а полнота 14 (классификатор нашел 25% всех спам-сообщений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "a = rf.predict(X_train)\n",
    "print(metrics.confusion_matrix(y_train, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The accuracy of prediction is:', accuracy_score(y_train, a))\n",
    "print('The roc_auc_score of prediction is:', roc_auc_score(y_train, a))\n",
    "print('The null acccuracy is:', max(y_test.mean(), 1 - y_train.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "a = rf.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The accuracy of prediction is:', accuracy_score(y_test, a))\n",
    "print('The roc_auc_score of prediction is:', roc_auc_score(y_test, a))\n",
    "print('The null acccuracy is:', max(y_test.mean(), 1 - y_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "a = rf.predict(data)\n",
    "print(metrics.confusion_matrix(y, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The accuracy of prediction is:', accuracy_score(y, a))\n",
    "print('The roc_auc_score of prediction is:', roc_auc_score(y, a))\n",
    "print('The null acccuracy is:', max(y_test.mean(), 1 - y.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = rf.predict_proba(data)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred_prob)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = rf.predict(data)\n",
    "pd.DataFrame(a).to_csv('prediction.csv')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг - lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(learning_rate = 0.125, metric = 'l1', \n",
    "                        n_estimators = 20, num_leaves = 38)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [x for x in range(50, 1050,50)],\n",
    "    'learning_rate': [ 0.01, 0.005,0.10, 0.125, 0.15, 0.175, 0.2]}\n",
    "gridsearch = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "gridsearch.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['auc', 'binary_logloss'],\n",
    "early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best parameters found by grid search are:', gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier(learning_rate = 0.175, metric = 'l1', \n",
    "                        n_estimators = 50, num_leaves = 38)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['auc', 'binary_logloss'],\n",
    "early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))\n",
    "print('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n",
    "print('The null acccuracy is:', max(y_test.mean(), 1 - y_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "y_pred_prob = gbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = lgb.plot_importance(gbm, height = 0.4, max_num_features=25, xlim = (0,100), ylim = (0,23), \n",
    "                         figsize = (10,6))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
